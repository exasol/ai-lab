{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5caa09-76ee-43d5-b999-b185b85ff046",
   "metadata": {},
   "source": [
    "# MAGIC Gamma Telescope\n",
    "\n",
    "In this notebook, we will load data simulating the registration of high-energy gamma particles in an atmospheric Cherenkov telescope. <a href=\"https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\" target=\"_blank\" rel=\"noopener\">Follow this link</a> to get details about this dataset.\n",
    "\n",
    "To execute queries and upload data to the Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the sandbox](../sandbox_config.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595cc77-885c-49ca-8385-b66a725fbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4f723-f2d2-4841-8dbf-6df3bde54a64",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "First, we will load the data into Pandas DataFrame. Each data column represents one of the features and is named accordingly, see section Additional Variable Information in the dataset description. We will name the Pandas columns as per the variable description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1e6a9-b640-419b-bc8e-b4379a43666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import tempfile\n",
    "from zipfile import ZipFile\n",
    "from contextlib import ExitStack\n",
    "import pandas as pd\n",
    "from stopwatch import Stopwatch\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "DATA_URL = \"https://archive.ics.uci.edu/static/public/159/magic+gamma+telescope.zip\"\n",
    "DATA_FILE = \"magic04.data\"\n",
    "\n",
    "resp = urlopen(DATA_URL)\n",
    "with ExitStack() as stack:\n",
    "    f = stack.enter_context(tempfile.TemporaryFile())\n",
    "    f.write(resp.read())\n",
    "    print(f\"Downloading the data took: {stopwatch}\")\n",
    "\n",
    "    f.seek(0)\n",
    "    z = stack.enter_context(ZipFile(f))\n",
    "    f = stack.enter_context(z.open(DATA_FILE, \"r\"))\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "column_names = [\n",
    "    'fLength',   # major axis of ellipse [mm]\n",
    "    'fWidth',    # minor axis of ellipse [mm] \n",
    "    'fSize',     # 10-log of the sum of the content of all pixels [in #phot]\n",
    "    'fConc',     # ratio of the sum of two highest pixels over fSize  [ratio]\n",
    "    'fConc1',    # ratio of highest pixel over fSize  [ratio]\n",
    "    'fAsym',     # distance from the highest pixel to center, projected onto major axis [mm]\n",
    "    'fM3Long',   # 3rd root of the third moment along major axis  [mm] \n",
    "    'fM3Trans',  # 3rd root of the third moment along minor axis  [mm]\n",
    "    'fAlpha',    # angle of major axis with vector to origin [deg]\n",
    "    'fDist',     # distance from the origin to the center of ellipse [mm]\n",
    "    'class'      # g,h - gamma (signal), hadron (background)\n",
    "]\n",
    "df.columns = column_names\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b6554-2b2e-4053-bea5-b69196218bfb",
   "metadata": {},
   "source": [
    "## Upload data into DB\n",
    "\n",
    "Let's split data randomly into train and test sets. We will then create two tables - TELESCOPE_TRAIN and TELESCOPE_TEST - and load the datasets into these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726bbfb-7d4b-4dbf-97f6-2c70260c1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from exasol.connections import open_pyexasol_connection\n",
    "\n",
    "# Split the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_table = 'TELESCOPE_TRAIN'\n",
    "test_table = 'TELESCOPE_TEST'\n",
    "column_desc = [f'{c} {(\"DECIMAL(18,4)\" if c.startswith(\"f\") else \"CHAR(1)\")}' for c in column_names]\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Create an Exasol connection\n",
    "with open_pyexasol_connection(sb_config, compression=True) as conn:\n",
    "\n",
    "    # Create tables\n",
    "    sql = f'CREATE OR REPLACE TABLE \"{sb_config.SCHEMA}\".\"{train_table}\"({\", \".join(column_desc)})'\n",
    "    conn.execute(query=sql)\n",
    "    sql = f'CREATE OR REPLACE TABLE \"{sb_config.SCHEMA}\".\"{test_table}\" LIKE \"{sb_config.SCHEMA}\".\"{train_table}\"'\n",
    "    conn.execute(query=sql)\n",
    "\n",
    "    # Import data into Exasol\n",
    "    conn.import_from_pandas(df_train, (sb_config.SCHEMA, train_table))\n",
    "    print(f\"Imported {conn.last_statement().rowcount()} rows into {train_table}.\")\n",
    "    conn.import_from_pandas(df_test, (sb_config.SCHEMA, test_table))\n",
    "    print(f\"Imported {conn.last_statement().rowcount()} rows into {test_table}.\")\n",
    "\n",
    "print(f\"Importing the data took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645e76c-6a6e-48f3-a668-c1fd8717d7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
