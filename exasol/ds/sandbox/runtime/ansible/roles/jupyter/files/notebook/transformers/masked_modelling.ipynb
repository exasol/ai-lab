{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25130b6-6e01-481a-91a0-838198be3ea8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/exasol/ai-lab/refs/heads/main/assets/Exasol_Logo_2025_Dark.svg\" style=\"width:200px; margin: 10px;\" />\n",
    "</div>\n",
    "\n",
    "# Fill-Mask model\n",
    "\n",
    "In this notebook, we will load and use a masked language model. This kind of model predicts which words would replace masked words in a sentence. Learn more about the Fill-Mask task <a href=\"https://huggingface.co/tasks/fill-mask\" target=\"_blank\" rel=\"noopener\">here</a>. Please also refer to the Transformer Extension <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a> to find more information about the UDF used in this notebook.\n",
    "\n",
    "We will be running SQL queries using <a href=\"https://github.com/ploomber/jupysql\" target=\"_blank\" rel=\"noopener\">JupySQL</a>SQL Magic.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the AI Lab](../main_config.ipynb).\n",
    "2. [Initialize the Transformer Extension](te_init.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Open Secure Configuration Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a1e16-acad-4f19-b105-a0e67de4a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff882542-d473-4767-a035-5c2615080cae",
   "metadata": {},
   "source": [
    "Let's bring up JupySQL and connect to the database via SQLAlchemy. Please refer to the documentation of <a href=\"https://github.com/exasol/sqlalchemy-exasol\" target=\"_blank\" rel=\"noopener\">sqlalchemy-exasol</a> for details on how to connect to the database using the Exasol SQLAlchemy driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc45d2-d5ae-4afc-9f1d-251923995990",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/jupysql_init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad672a-8b26-467b-8649-0bf95b1efb61",
   "metadata": {},
   "source": [
    "## Get a language model\n",
    "\n",
    "To demonstrate the filling of a masked word task we will use a [RadBERT model](https://huggingface.co/StanfordAIMI/RadBERT) which was pre-trained on radiology reports.\n",
    "\n",
    "We need to load the model from the Hugging Face Hub into the [BucketFS](https://docs.exasol.com/db/latest/database_concepts/bucketfs/bucketfs.htm). This could potentially be a long process, depending on the speed of the database connection. Unfortunately, we cannot tell exactly when it has finished. The notebook's hourglass may not be a reliable indicator. [BucketFS](https://docs.exasol.com/db/latest/database_concepts/bucketfs/bucketfs.htm) will still be doing some work when the call issued by the notebook returns. Please wait for a few moments after that, before querying the model.\n",
    "\n",
    "You might see a warning that some weights are newly initialized and the model should be trained on a down-stream task. Please ignore this warning. For the purpose of this demonstration, it is not important, the model should still be able to produce some meaningful output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede4beb-9bfe-413c-846a-a2e5c6eaa784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exasol.nb_connector.model_installation import install_model, TransformerModel\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "# This is the name of the model at the Hugging Face Hub\n",
    "MODEL_NAME = 'StanfordAIMI/RadBERT'\n",
    "install_model(ai_lab_config, TransformerModel(MODEL_NAME, 'filling_mask', AutoModelForMaskedLM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825231e-f7fa-4011-9d11-f94890f6ba7d",
   "metadata": {},
   "source": [
    "## Use the language model\n",
    "\n",
    "Let's see if the model can fill in a masked word in the following text. We will be using the TE_FILLING_MASK_UDF` for this. We will use an patient-instruction as the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca587eb-3213-4089-a844-4bb89cf1afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sentence with a masked word that will be given to the model.\n",
    "# It instruction usually given to a patient when a radiographer is doing a chest X-ray\n",
    "MY_TEXT = 'Take a deep [MASK] and hold it'\n",
    "\n",
    "# Make sure our text can be used in an SQL statement.\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3727075-4680-4f2f-83c2-17e5c22c6a57",
   "metadata": {},
   "source": [
    "The udf takes various input parameters:\n",
    "\n",
    "* device_id: To run the UDF on a GPU, specify the valid cuda device ID.\n",
    "* bucketfs_conn: The BucketFS connection name.\n",
    "* sub_dir: The directory where the model is stored in the BucketFS.\n",
    "* model_name: The name of the model to use for prediction.\n",
    "* text_data: The text data containing masking tokens.\n",
    "* top_k: The number of predictions to return.\n",
    "\n",
    "We will collect the 5 best answers.\n",
    "We will save the result in the variable `udf_output` to support automatic testing of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8288e3-0658-44a3-8fc6-92d6e1c4b3f1",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "running_model"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save udf_output\n",
    "WITH MODEL_OUTPUT AS\n",
    "(\n",
    "    SELECT TE_FILLING_MASK_UDF(\n",
    "        NULL,\n",
    "        '{{ai_lab_config.bfs_connection_name}}',\n",
    "        '{{ai_lab_config.bfs_model_subdir}}',\n",
    "        '{{MODEL_NAME}}',\n",
    "        '{{MY_TEXT}}',\n",
    "        5\n",
    "    )\n",
    ")\n",
    "SELECT filled_text, score, rank, error_message FROM MODEL_OUTPUT ORDER BY SCORE DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c4047-2cbb-4111-a932-0224844c0f43",
   "metadata": {},
   "source": [
    "We select only some of the udf's output columns in these examples.  If you need more details, you can find information on all available output columns in the <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a>.\n",
    "\n",
    "The output of the model is sorted into the following columns by the udf:\n",
    "\n",
    "* filled_text: the filled text which replaces the masked part od the input text\n",
    "* score: the confidence, with which the filled_text was predicted\n",
    "* rank: the rank of the prediction. In this context, all predictions/labels for one input are ranked by their score. rank=1 means best result/highest score.\n",
    "* error_message: error occurring while executing the udf will be saved here\n",
    "\n",
    "\n",
    "The code above shows how the model works on a toy example. However, the main purpose of having a model deployed in the database is to get a quick response for a batch input. The performance gain comes from two factors - localization and parallelization. The first means that the input data never crosses the machine boundaries. The second means that multiple instances of the model are processing the data on all available nodes in parallel.\n",
    "\n",
    "Another advantage of making predictions within the database is enhanced data security. The task of safeguarding privacy can be simplified given the fact that the source data never leaves the database machine.\n",
    "\n",
    "In a more practical application, the input text would be stored in a column of a database table. For example, if we wanted to get the best answer for each row of the input table `MY_TEXT_TABLE`, where text with a masked word is in the column `MY_TEXT_COLUMN`, the SQL would look similar to this:\n",
    "```\n",
    "SELECT TE_FILLING_MASK_UDF(..., MY_TEXT_COLUMN, 1) FROM MY_TEXT_TABLE;\n",
    "```\n",
    "Please note, that the response time observed on the provided example with a single input will not be scaled up linearly in case of multiple inputs. Much of the latency falls on loading the model into the CPU memory from BucketFS. This needs to be done only once regardless of the number of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00934fda-f64e-45f4-9686-c37cf34ea500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
