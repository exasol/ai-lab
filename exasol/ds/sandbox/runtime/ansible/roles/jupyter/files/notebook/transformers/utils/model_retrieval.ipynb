{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e01c65-a263-48a9-8c45-51c5d0123f49",
   "metadata": {},
   "source": [
    "# Load Model from Huggingface Hub\n",
    "\n",
    "To use a model with the Transformer Extension one needs to download it from the Huggingface Hub and put it into the BucketFS. Please refer to the Transformer Extension <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a> to find more information about model loading functionality it provides.\n",
    "\n",
    "There are two ways of doing this.\n",
    "\n",
    "1. Using the TE_MODEL_DOWNLOADER_UDF UDF.\n",
    "2. Downloading a model to a local drive and subsequently uploading it into the BucketFS using CLI or an API.\n",
    "\n",
    "The first method requires the database machine to have internet access. The second method provides a workaround if this is a problem. Another advantage of the second method is that it caches downloaded models on the local drive. This can make the model transfer quicker if it needs to be repeated.\n",
    "\n",
    "<b>This notebook is not supposed to be run on its own. It contains model loading functions that are called by other notebooks.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e9765-c67b-4f85-85c2-c7bb99a464ac",
   "metadata": {},
   "source": [
    "## Loading model with UDF\n",
    "\n",
    "Here is the first way of loading the model. We wrap it into a function so that other notebooks can call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d88d33-8028-4843-a05c-ff4ddb7b02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_huggingface_model_udf(model_name: str, conf: \"Secrets\") -> None:\n",
    "    \"\"\"\n",
    "    Loads specified model into BucketFS using a UDF provided with the Transformer Extension.\n",
    "\n",
    "    model_name     - Name of the model at Huggingface hub, e.g. facebook/nllb-moe-54b.\n",
    "    conf           - Sandbox configuration object.\n",
    "    \"\"\"\n",
    "\n",
    "    import pyexasol\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT {sb_config.SCHEMA}.TE_MODEL_DOWNLOADER_UDF(\n",
    "        '{model_name}',\n",
    "        '{sb_config.TE_MODELS_BFS_DIR}',\n",
    "        '{sb_config.TE_BFS_CONN}',\n",
    "        '{sb_config.TE_TOKEN_CONN}'\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    dsn = f'{sb_config.EXTERNAL_HOST_NAME}:{sb_config.HOST_PORT}'\n",
    "    with pyexasol.connect(dsn=dsn, user=sb_config.USER, password=sb_config.PASSWORD, compression=True) as conn:\n",
    "        conn.execute(query=sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187f53b-e9c1-4376-800f-50571dce0b06",
   "metadata": {},
   "source": [
    "## Loading model using the notebook\n",
    "\n",
    "Here is the second way of loading the model. This method is very similar to the command line interface. For details on how to use the CLI please refer to the Transformer Extension <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d00ad-4e99-4f4b-888c-78a080142d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_huggingface_model_cli(model_name: str, conf: \"Secrets\", force_download: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Loads specified model into BucketFS by saving it first to a local drive, as per the command-line interface.\n",
    "\n",
    "    model_name     - Name of the model at Huggingface hub, e.g. facebook/nllb-moe-54b.\n",
    "    conf           - Sandbox configuration object.\n",
    "    force_download - If True the model will be reloaded from the hub even if it has been cached before.\n",
    "    \"\"\"\n",
    "\n",
    "    from pathlib import Path\n",
    "    import re\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    from exasol_transformers_extension.utils.bucketfs_operations import (\n",
    "        create_bucketfs_location, get_model_path, upload_model_files_to_bucketfs)\n",
    "\n",
    "    # Make a name for the model sub-directory\n",
    "    sub_dir = re.sub(r\"[/\\\\?%*:|\\\"<>\\x7F\\x00-\\x1F]\", \"-\", model_name)\n",
    "    model_dir = str(Path(conf.get('TE_MODELS_CACHE_DIR')) / sub_dir)\n",
    "    \n",
    "    # Maybe download the model from the Huggingface hub\n",
    "    AutoTokenizer.from_pretrained(model_name, cache_dir=model_dir, token=sb_config.TE_TOKEN, force_download=force_download)\n",
    "    AutoModel.from_pretrained(model_name, cache_dir=model_dir, token=sb_config.TE_TOKEN, force_download=force_download)\n",
    "\n",
    "    # Create bucketfs location\n",
    "    bucketfs_location = create_bucketfs_location(\n",
    "        conf.get('BUCKETFS_SERVICE'), conf.get('EXTERNAL_HOST_NAME'), int(conf.get('BUCKETFS_PORT')),\n",
    "        conf.get('BUCKETFS_USE_HTTPS').lower() == 'true', conf.get('BUCKETFS_USER'), conf.get('BUCKETFS_PASSWORD'), \n",
    "        conf.get('BUCKETFS_BUCKET'), conf.get('TE_BFS_DIR'))\n",
    "\n",
    "    # Upload the downloaded model files into bucketfs\n",
    "    upload_path = get_model_path(conf.get('TE_MODELS_BFS_DIR'), model_name)\n",
    "    upload_model_files_to_bucketfs(model_dir, upload_path, bucketfs_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332928b-6ee5-4a04-aca3-4e60c93836f5",
   "metadata": {},
   "source": [
    "## Method selector\n",
    "\n",
    "This is the main entry point. The call will be dispatched to one of the above functions depending on the selected method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4968774-3054-4762-8d0a-462c7cc712c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_huggingface_model(model_name: str, conf: \"Secrets\", method: str = None, force_download: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Loads specified model into BucketFS choosing one of the two available methods.\n",
    "\n",
    "    model_name     - Name of the model at Huggingface hub, e.g. facebook/nllb-moe-54b.\n",
    "    conf           - Sandbox configuration object.\n",
    "    method         - The recognized values are \"udf\" and \"cli\". If the parameter is not set then\n",
    "                     will look for method selection in the configuration. That failed the CLI method\n",
    "                     is used. \n",
    "    force_download - If True the model will be reloaded from the hub even if it has been cached before.\n",
    "    \"\"\"\n",
    "\n",
    "    if not method:\n",
    "        method = conf.get('TE_LOAD_METHOD')\n",
    "    if method:\n",
    "        method = method.lower()\n",
    "    if method == 'udf':\n",
    "        load_huggingface_model_udf(model_name, conf)\n",
    "    else:\n",
    "        load_huggingface_model_cli(model_name, conf, force_download=force_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc718d-6811-4963-9a65-bb030eae711e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
