{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c42f7dd-9bbe-4c68-a678-d233a7bb30e8",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "In this notebook, we are going to train a binary classification model using AWS SageMaker ML Autopilot. The SageMaker Extension provides a script that starts this process. It uploads the training data into the selected S3 bucket, then creates and starts the Autopilot job. Please refer to the Extension <a href=\"https://github.com/exasol/sagemaker-extension/blob/main/doc/user_guide/user_guide.md#execution-of-training\" target=\"_blank\" rel=\"noopener\">User Guide</a> for a detailed description of the service.\n",
    "\n",
    "We will be running SQL queries using <a href=\"https://jupysql.ploomber.io/en/latest/quick-start.html\" target=\"_blank\" rel=\"noopener\"> JupySQL</a> SQL Magic.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the sandbox](../sandbox_config.ipynb).\n",
    "2. [Initialize the SageMaker Extension](sme_init.ipynb).\n",
    "3. [Load the MAGIC Gamma Telescope data](../data/data_telescope.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db14ca-92d5-4be0-bdd1-a0e45e3cabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6e4ce-f05e-4810-bb68-356d63042ad4",
   "metadata": {},
   "source": [
    "### Job name\n",
    "\n",
    "We need a new unique job name. We will make it up from the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e8285-9794-45cb-bfaa-d8e1f6fe45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "sb_config.save('JOB_NAME', 'CLS' + datetime.now().strftime('%Y%m%d%H%M%S'))\n",
    "\n",
    "# Here is the job name we are going to use in this and the following notebooks.\n",
    "sb_config.JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e952b4-8724-46f9-a15a-7de2f306883f",
   "metadata": {},
   "source": [
    "Let's bring up JupySQL and connect to the database via SQLAlchemy. Please refer to the documentation of <a href=\"https://github.com/exasol/sqlalchemy-exasol\" target=\"_blank\" rel=\"noopener\">sqlalchemy-exasol</a> for details on how to connect to the database using Exasol SQLAlchemy driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c336a-6461-4d32-a448-160fc72baedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/jupysql_init.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0753272-319f-4745-bb05-74922a4d2379",
   "metadata": {},
   "source": [
    "## Start training\n",
    "\n",
    "Let's define a few variables for our experiment.\n",
    "\n",
    "<b>Note that the path for input data should be unique for each experiment.</b>. Alternatively, all data files should be cleared after the experiment is finished. Currently, this has to be done manually. The Autopilot will be using all data files found in this directory. If it contains stale files from previous experiments then at best the training pipeline will fail. Or worse, a wrong model will be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb26cd-17a9-4faa-bf47-b3ec63e0be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URI of the S3 bucket\n",
    "S3_BUCKET_URI=f\"s3://{sb_config.AWS_BUCKET}\"\n",
    "\n",
    "# Path in the S3 bucket where the input data will be uploaded.\n",
    "S3_OUTPUT_PATH = \"ida_dataset_path\"\n",
    "\n",
    "# Input table name.\n",
    "INPUT_TABLE_NAME = \"TELESCOPE_TRAIN\"\n",
    "\n",
    "# Name of the view extending input table (see below why it is necessary).\n",
    "INPUT_VIEW_NAME = \"Z_\" + INPUT_TABLE_NAME\n",
    "\n",
    "# Name of the column in the input table which is the prediction target.\n",
    "TARGET_COLUMN = \"CLASS\"\n",
    "\n",
    "# The maximum number of model candidates.\n",
    "MAX_CANDIDATES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d7ae3-6ab9-4872-9f7f-a0b10fd91f5b",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "When we use our model for making batch predictions we will need to identify samples in the batch. This is because the order of labeled samples in the output may not match the order of unlabeled samples in the input. For that purpose, we will extend features by adding an artificial column that will be a placeholder for a sample ID. During model training, we will set this column to a constant value. This should make it non-influential for the prediction.\n",
    "\n",
    "Future versions of the SageMaker Extension are expected to be doing this step for us.\n",
    "\n",
    "First, we need to get a list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c1344-7c55-4c70-bc3c-20da40c25646",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql column_names <<\n",
    "SELECT COLUMN_NAME\n",
    "FROM SYS.EXA_ALL_COLUMNS\n",
    "WHERE COLUMN_SCHEMA = '{{sb_config.SCHEMA}}' AND COLUMN_TABLE='{{INPUT_TABLE_NAME}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec03337-68df-44e7-89ea-d59f76ce0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ', '.join(f'[{name[0]}]' for name in column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac423e-ba2a-45a5-93aa-6ec4e78d4e61",
   "metadata": {},
   "source": [
    "Now let's create a view extending the input table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41838507-4b7b-4312-8f1e-8303e75e3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW {{sb_config.SCHEMA}}.\"{{INPUT_VIEW_NAME}}\" AS\n",
    "SELECT CAST(0 AS INT) AS SAMPLE_ID, {{column_names}} FROM {{INPUT_TABLE_NAME}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6199a-47c1-4321-906d-dd5d88956bf3",
   "metadata": {},
   "source": [
    "### Create Autopilot job\n",
    "\n",
    "The script below exports the data to the AWS S3 bucket. This export operation is highly efficient, as it is performed in parallel. After that it calls Amazon SageMaker Autopilot, which automatically performs an end-to-end machine learning development, to build a model. The script doesn't wait till the training is completed. That may take a while. The next script will allow us to monitor the progress of the Autopilot training pipeline.\n",
    "\n",
    "<img src=\"utils/sme_training.png\"/>\n",
    "<center>Model training with Autopilot</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25609a4d-d0b9-4e3c-abd8-3543fe49b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.named_parameters=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766a29b-7b51-44ec-9a72-0024366a4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "EXECUTE SCRIPT \"{{sb_config.SCHEMA}}\".\"SME_TRAIN_WITH_SAGEMAKER_AUTOPILOT\"(\n",
    "'{\n",
    "    \"job_name\"                          : \"{{sb_config.JOB_NAME}}\",\n",
    "    \"aws_credentials_connection_name\"   : \"{{sb_config.SME_AWS_CONN}}\",\n",
    "    \"aws_region\"                        : \"{{sb_config.AWS_REGION}}\",\n",
    "    \"iam_sagemaker_role\"                : \"{{sb_config.AWS_ROLE}}\",\n",
    "    \"s3_bucket_uri\"                     : \"{{S3_BUCKET_URI}}\",\n",
    "    \"s3_output_path\"                    : \"{{S3_OUTPUT_PATH}}\",\n",
    "    \"input_schema_name\"                 : \"{{sb_config.SCHEMA}}\",\n",
    "    \"input_table_or_view_name\"          : \"{{INPUT_VIEW_NAME}}\",\n",
    "    \"target_attribute_name\"             : \"{{TARGET_COLUMN}}\",\n",
    "    \"max_candidates\"                    : {{MAX_CANDIDATES}}\n",
    "}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96dfed-bfd1-4a2e-9721-f05a67347308",
   "metadata": {},
   "source": [
    "We don't need the input view anymore since the data has been uploaded into an S3 bucket. Let's delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac19655-5ac1-4f88-8ff1-d8df8fb5dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP VIEW {{sb_config.SCHEMA}}.\"{{INPUT_VIEW_NAME}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82260f-64f5-441e-a5cb-f0b65eea4649",
   "metadata": {},
   "source": [
    "## Poll training status\n",
    "\n",
    "As it was mentioned above, the model training runs asynchronously. We can monitor its progress by polling the Autopilot job status. Please call this script periodically until you see the status as Completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b74a02-4e2d-4a96-be01-cf9658976472",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "EXECUTE SCRIPT {{sb_config.get(\"SCHEMA\")}}.\"SME_POLL_SAGEMAKER_AUTOPILOT_JOB_STATUS\"(\n",
    "    '{{sb_config.JOB_NAME}}',\n",
    "    '{{sb_config.SME_AWS_CONN}}',\n",
    "    '{{sb_config.AWS_REGION}}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e772fc-6d58-4e51-9aa2-e4230ded8f08",
   "metadata": {},
   "source": [
    "Once the job status becomes `Completed` the model is ready to be deployed and used for prediction. This will be demonstrated in the [next notebook](sme_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fc13e-51b9-4910-bcea-10d73e6bcfa0",
   "metadata": {},
   "source": [
    "## Troubleshoot the job\n",
    "\n",
    "If the job fails the code below may help with troubleshooting. It prints a detailed description of the job status including the reason for failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fde837-3e50-4c9d-b094-aac987b04575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker import AutoML\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = sb_config.AWS_REGION\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = sb_config.AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = sb_config.AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "automl = AutoML.attach(auto_ml_job_name=sb_config.JOB_NAME)\n",
    "automl.describe_auto_ml_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0992f-f9eb-4003-8b29-46afc8bcff97",
   "metadata": {},
   "source": [
    "Another hint is to check that the input data has been uploaded to the S3 bucket correctly. Generally, the data will be split into a number of batches. The following command will print a list of CSV files, one per batch. The name of a file is made of the name of the input data view and the batch number. There should be no other files in the input data directory.\n",
    "\n",
    "The files can be inspected further by downloading them to a local machine with `aws s3 cp` command.\n",
    "\n",
    "We assume that the required environment variables have been set when executing the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc43fbb-3e32-4e89-b333-4bde25304e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_command = f'aws s3 ls s3://{sb_config.AWS_BUCKET}/{S3_OUTPUT_PATH} --recursive'\n",
    "!{aws_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec818e0-2fd9-4744-9c56-953e335850f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
