{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30001487-61d5-46be-a662-83f406d8cc2a",
   "metadata": {},
   "source": [
    "# Abalone\n",
    "\n",
    "Here we will load data of physical measurements of abalones (sea snails). <a href=\"https://archive.ics.uci.edu/dataset/1/abalone\" target=\"_blank\" rel=\"noopener\">Follow this link</a> to get details about this dataset.\n",
    "\n",
    "To execute queries and upload data to Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the sandbox](../sandbox_config.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fd009-42ca-4b16-929a-d00d284e2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97740f-c9b6-40f8-a9c7-3ddcd08e0898",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "First, we will load the data into Pandas DataFrame. Each data column represents one of the features and is named accordingly, see section Variable Table in the dataset description. We will name the Pandas columns as per the variable description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b0429-1fe3-46ae-9569-a08c11c78464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import tempfile\n",
    "from zipfile import ZipFile\n",
    "from contextlib import ExitStack\n",
    "import pandas as pd\n",
    "from stopwatch import Stopwatch\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "DATA_URL = \"https://archive.ics.uci.edu/static/public/1/abalone.zip\"\n",
    "DATA_FILE = \"abalone.data\"\n",
    "\n",
    "resp = urlopen(DATA_URL)\n",
    "with ExitStack() as stack:\n",
    "    f = stack.enter_context(tempfile.TemporaryFile())\n",
    "    f.write(resp.read())\n",
    "    print(f\"Downloading the data took: {stopwatch}\")\n",
    "\n",
    "    f.seek(0)\n",
    "    z = stack.enter_context(ZipFile(f))\n",
    "    f = stack.enter_context(z.open(DATA_FILE, \"r\"))\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "column_def = [\n",
    "    ('Sex', 'CHAR(1)'),\t                 # M, F, and I (infant)\n",
    "    ('Length', 'DECIMAL(4,3)'),          # longest shell measurement (mm)\n",
    "    ('Diameter', 'DECIMAL(4,3)'),\t     # perpendicular to length (mm)\n",
    "    ('Height', 'DECIMAL(4,3)'),          # with meat in shell (mm)\n",
    "    ('Whole_weight', 'DECIMAL(5,4)'),    # whole abalone (grams)\n",
    "    ('Shucked_weight', 'DECIMAL(5,4)'),  # weight of meat (grams)\n",
    "    ('Viscera_weight', 'DECIMAL(5,4)'),  # gut weight (after bleeding) (grams)\n",
    "    ('Shell_weight', 'DECIMAL(4,3)'),    # after being dried (grams)\n",
    "    ('Rings', 'INT')                     # +1.5 gives the age in years\n",
    "]\n",
    "df.columns = [name for name, _ in column_def]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ba87d-57f4-44f6-a0f8-8c5556afb719",
   "metadata": {},
   "source": [
    "## Upload data into DB\n",
    "\n",
    "Let's split data randomly into train and test sets. We will then create two tables - ABALONE_TRAIN and ABALONE_TEST - and load the datasets into these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547907a7-b437-4ff4-8ab8-08b55e0dcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from exasol.connections import open_pyexasol_connection\n",
    "\n",
    "# Split the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_table = 'ABALONE_TRAIN'\n",
    "test_table = 'ABALONE_TEST'\n",
    "column_desc = [' '.join(c) for c in column_def]\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Create an Exasol connection\n",
    "with open_pyexasol_connection(sb_config, compression=True) as conn:\n",
    "\n",
    "    # Create tables\n",
    "    sql = f'CREATE OR REPLACE TABLE \"{sb_config.SCHEMA}\".\"{train_table}\"({\", \".join(column_desc)})'\n",
    "    conn.execute(query=sql)\n",
    "    sql = f'CREATE OR REPLACE TABLE \"{sb_config.SCHEMA}\".\"{test_table}\" LIKE \"{sb_config.SCHEMA}\".\"{train_table}\"'\n",
    "    conn.execute(query=sql)\n",
    "\n",
    "    # Import data into Exasol\n",
    "    conn.import_from_pandas(df_train, (sb_config.SCHEMA, train_table))\n",
    "    print(f\"Imported {conn.last_statement().rowcount()} rows into {train_table}.\")\n",
    "    conn.import_from_pandas(df_test, (sb_config.SCHEMA, test_table))\n",
    "    print(f\"Imported {conn.last_statement().rowcount()} rows into {test_table}.\")\n",
    "\n",
    "print(f\"Importing the data took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0456f4-7e8f-4942-8653-c81f71508291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
