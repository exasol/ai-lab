{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5198ad82-d819-48d8-9f76-639fe4de4d26",
   "metadata": {},
   "source": [
    "# Predicting with Classification Model\n",
    "\n",
    "In this notebook, we will use a <a href=\"https://scikit-learn.org/stable/\" target=\"_blank\" rel=\"noopener\">`scikit-learn`</a> model created earlier to classify the radiation source of Cherenkov shower images. You can find more information about the problem domain <a href=\"https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\" target=\"_blank\" rel=\"noopener\">here</a>.\n",
    "\n",
    "We will be using a generic prediction UDF script. To execute queries and load data from the Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Create generic scikit-learn prediction UDF script](sklearn_predict_udf.ipynb).\n",
    "2. [Train a model on the MAGIC Gamma Telescope dataset](sklearn_train_telescope.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea932d-b2b6-429e-b6f5-d0caae45f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc1450-9210-4189-82b0-c67d5d53a307",
   "metadata": {},
   "source": [
    "## Run predictions\n",
    "\n",
    "Let's classify the data we have in the table `TELESCOPE_TEST`. This table also includes a column with ground truth labels. We will use it to assess the performance of our classifier. In the code below we will add the ROWID to the output columns (as required by the generic prediction UDF). This will allow us to link the result to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a346f-bb6a-4840-850b-75514a28c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exasol.connections import open_pyexasol_connection, get_udf_bucket_path\n",
    "from stopwatch import Stopwatch\n",
    "\n",
    "target_column = 'CLASS'\n",
    "bfs_model_path = get_udf_bucket_path(sb_config) + '/telescope_tree_model.pkl'\n",
    "params = {'schema': sb_config.SCHEMA, 'test_table': 'TELESCOPE_TEST', 'model_path': bfs_model_path}\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "with open_pyexasol_connection(sb_config, compression=True) as conn:\n",
    "    # Get the list of feature columns\n",
    "    sql = 'SELECT * FROM {schema!i}.{test_table!i} LIMIT 1'\n",
    "    df_tmp = conn.export_to_pandas(query_or_table=sql, query_params=params)\n",
    "    params['column_names'] = [f'[{c}]' for c in df_tmp.columns if c != target_column]\n",
    "\n",
    "    # Get the predictions for all rows in the TEST table calling the prediction UDF.\n",
    "    # Provide the model path and the row ID in the first two parameters.\n",
    "    sql = f'SELECT {{schema!q}}.SKLEARN_PREDICT({{model_path!s}}, ROWID, {{column_names!r}}) ' \\\n",
    "        f'emits ([sample_id] DECIMAL(20,0), [{target_column}] CHAR(1)) FROM {{schema!q}}.{{test_table!q}}'\n",
    "    df_pred = conn.export_to_pandas(query_or_table=sql, query_params=params)\n",
    "\n",
    "print(f\"Getting predictions took: {stopwatch}\")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0226216f-0d7e-4e06-af8f-6f9af6bbd845",
   "metadata": {},
   "source": [
    "## Evaluate predictions\n",
    "\n",
    "We are going to check the performance of our classifier by linking the results to the ground truth labels and computing the confusion matrix. This should give us similar results to what we have seen in the [training notebook](sklearn_train_telescope.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf50dc2-d457-499b-b97d-e9c07c49398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the ground truth labels for the test set.\n",
    "with open_pyexasol_connection(sb_config, compression=True) as conn:\n",
    "    sql = f'SELECT ROWID AS [sample_id], [{target_column}] FROM {{schema!q}}.{{test_table!q}}'\n",
    "    df_true = conn.export_to_pandas(query_or_table=sql, query_params=params)\n",
    "\n",
    "# Merge predictions and the ground truth on the sample ID.\n",
    "df_res = pd.merge(left=df_true, right=df_pred, on='sample_id', suffixes=['_true', '_pred'])\n",
    "\n",
    "# Get the label names\n",
    "labels=df_res[f'{target_column}_true'].unique()\n",
    "\n",
    "# Build and display the confusion matrix.\n",
    "cm = confusion_matrix(df_res[f'{target_column}_true'], df_res[f'{target_column}_pred'], labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b14081-9fd2-4f50-b3fb-bb424c31b73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
