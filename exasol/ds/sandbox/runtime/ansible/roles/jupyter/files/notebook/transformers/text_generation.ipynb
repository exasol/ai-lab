{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73a1de2-05df-49ab-bec9-897f11dbe9a9",
   "metadata": {},
   "source": [
    "# Generative text model\n",
    "\n",
    "In this notebook, we will load and use a generative language model that can produce a continuation for a given text. Learn more about the Text Generation task <a href=\"https://huggingface.co/tasks/text-generation\" target=\"_blank\" rel=\"noopener\">here</a>. Please also refer to the Transformer Extension <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a> to find more information about the UDF used in this notebook.\n",
    "\n",
    "To execute queries and load data from Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the sandbox](../sandbox_config.ipynb).\n",
    "2. [Initialize the Transformer Extension](te_init.ipynb).\n",
    "\n",
    "## Set up\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22caa07-85b9-47a4-bef6-007fec786f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e007de9-7ecf-4bb9-84f1-cfb3688f9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTERNAL_HOST = f\"{sb_config.EXTERNAL_HOST_NAME}:{sb_config.HOST_PORT}\"\n",
    "\n",
    "WEBSOCKET_URL = f\"exa+websocket://{sb_config.USER}:{sb_config.PASSWORD}\" \\\n",
    "    f\"@{EXTERNAL_HOST}/{sb_config.SCHEMA}?SSLCertificate=SSL_VERIFY_NONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d11a1d4-051d-4d21-990a-660beaeb8f0c",
   "metadata": {},
   "source": [
    "## Get language model\n",
    "\n",
    "To demonstrate the text generation task we will use [Open Pretrained Transformers (OPT)](https://huggingface.co/facebook/opt-125m), a decoder-only pre-trained transformer from Facebook.\n",
    "\n",
    "We need to load the model from the Huggingface hub into the BucketFS. This could potentially be a long process. Unfortunately, we cannot tell exactly when it has finished. The notebook's hourglass may not be a reliable indicator. BucketFS will still be doing some work when the call issued by the notebook returns. Please wait for a few moments after that, before querying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c9b44-93a0-4df3-9a8e-54e182027d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the name of the model at the Huggingface Hub\n",
    "MODEL_NAME = 'facebook/opt-125m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57029a52-064b-4fda-80bf-289cce50ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/model_retrieval.ipynb\n",
    "load_huggingface_model(MODEL_NAME, sb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efa927-aa78-4b80-9b78-25e722904217",
   "metadata": {},
   "source": [
    "## Use language model\n",
    "\n",
    "Let's put the start of our conversation in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3998b7-d886-4b0c-b0d2-92e54cc27b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_TEXT = 'The bar-headed goose can fly at much'\n",
    "\n",
    "# Make sure our texts can be used in an SQL statement.\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56498899-79f8-471e-8337-983184dcd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put a limit on the length of text the model can generate in one call.\n",
    "# The limit is specified in the number of characters.\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a45b81-29e3-40f8-9bb8-4b7a5c6eb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyexasol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1dd67-ffed-4bf8-9ee7-a1e003cdbcc6",
   "metadata": {},
   "source": [
    "We will be updating this variable at every call to the model.\n",
    "Please run the next cell multiple times to see how the text evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0d826-519a-4e03-9ce0-3827d0756f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT {sb_config.SCHEMA}.TE_TEXT_GENERATION_UDF(\n",
    "    NULL,\n",
    "    '{sb_config.TE_BFS_CONN}',\n",
    "    '{sb_config.TE_TOKEN_CONN}',\n",
    "    '{sb_config.TE_MODELS_BFS_DIR}',\n",
    "    '{MODEL_NAME}',\n",
    "    '{MY_TEXT}',\n",
    "    {MAX_LENGTH},\n",
    "    True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with pyexasol.connect(dsn=EXTERNAL_HOST, user=sb_config.USER, password=sb_config.PASSWORD, compression=True) as conn:\n",
    "    result = conn.export_to_pandas(query_or_table=sql).squeeze()\n",
    "    MY_TEXT = result['GENERATED_TEXT']\n",
    "    # The error can be observed at result['ERROR_MESSAGE']\n",
    "\n",
    "print(MY_TEXT)\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30974b1a-a5b5-44d9-97c8-774be0dd4608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
