{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73a1de2-05df-49ab-bec9-897f11dbe9a9",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/exasol/ai-lab/refs/heads/main/assets/Exasol_Logo_2025_Dark.svg\" style=\"width:200px; margin: 10px;\" />\n",
    "</div>\n",
    "\n",
    "# Generative text model\n",
    "\n",
    "In this notebook, we will load and use a generative language model that can produce a continuation for a given text. Learn more about the Text Generation task <a href=\"https://huggingface.co/tasks/text-generation\" target=\"_blank\" rel=\"noopener\">here</a>. Please also refer to the Transformer Extension <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a> to find more information about the UDF used in this notebook.\n",
    "\n",
    "To execute queries and load data from the Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the AI Lab](../main_config.ipynb).\n",
    "2. [Initialize the Transformer Extension](te_init.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Open Secure Configuration Storage"
   ]
  },
  {
   "cell_type": "code",
   "id": "f22caa07-85b9-47a4-bef6-007fec786f96",
   "metadata": {},
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6d11a1d4-051d-4d21-990a-660beaeb8f0c",
   "metadata": {},
   "source": [
    "## Get a language model\n",
    "\n",
    "To demonstrate the text generation task we will use [Open Pretrained Transformers (OPT)](https://huggingface.co/facebook/opt-125m), a decoder-only pre-trained transformer from Facebook.\n",
    "\n",
    "We need to load the model from the Hugging Face Hub into the [BucketFS](https://docs.exasol.com/db/latest/database_concepts/bucketfs/bucketfs.htm). This could potentially be a long process, depending on the connection of the Database. Unfortunately, we cannot tell exactly when it has finished. The notebook's hourglass may not be a reliable indicator. BucketFS will still be doing some work when the call issued by the notebook returns. Please wait for a few moments after that, before querying the model.\n",
    "\n",
    "You might see a warning that some weights are newly initialized and the model should be trained on a down-stream task. Please ignore this warning. For the purpose of this demonstration, it is not important, the model should still be able to produce some meaningful output."
   ]
  },
  {
   "cell_type": "code",
   "id": "d73c9b44-93a0-4df3-9a8e-54e182027d61",
   "metadata": {},
   "source": [
    "from exasol.nb_connector.model_installation import install_model, TransformerModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# This is the name of the model at the Hugging Face Hub\n",
    "MODEL_NAME = 'facebook/opt-125m'\n",
    "install_model(ai_lab_config, TransformerModel(MODEL_NAME, 'text_generation', AutoModelForCausalLM))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b4efa927-aa78-4b80-9b78-25e722904217",
   "metadata": {},
   "source": [
    "## Use the language model\n",
    "\n",
    "Let's put our starting text in a variable. We will feed this text to the `TE_TEXT_GENERATION_UDF`, which will use the previously downloaded model to generate a continuation of the input text."
   ]
  },
  {
   "cell_type": "code",
   "id": "aa3998b7-d886-4b0c-b0d2-92e54cc27b91",
   "metadata": {},
   "source": [
    "MY_TEXT = 'The bar-headed goose can fly at much'\n",
    "\n",
    "# Make sure our texts can be used in an SQL statement.\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94a45b81-29e3-40f8-9bb8-4b7a5c6eb28c",
   "metadata": {},
   "source": [
    "from exasol.nb_connector.connections import open_pyexasol_connection\n",
    "from exasol.nb_connector.language_container_activation import get_activation_sql\n",
    "\n",
    "# We will be creating a new database session every time we call the model.\n",
    "# We will have to activate the language container for each of these sessions.\n",
    "# Here we will get the activation SQL command.\n",
    "activation_sql = get_activation_sql(ai_lab_config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27b1dd67-ffed-4bf8-9ee7-a1e003cdbcc6",
   "metadata": {},
   "source": [
    "The udf takes various input parameters:\n",
    "\n",
    "* device_id: To run on a GPU, specify the valid cuda device ID.\n",
    "* bucketfs_conn: The BucketFS connection name.\n",
    "* sub_dir: The directory where the model is stored in the BucketFS.\n",
    "* model_name: The name of the model to use for prediction.\n",
    "* text_data: The text continue.\n",
    "* max_length: The maximum total length of text to be generated.\n",
    "* return_full_text: If set to FALSE, only added text is returned, otherwise the full text is returned.\n",
    "\n",
    "You need to supply these parameters in the correct order. Further information can be found in the  <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a>.\n",
    "\n",
    "We will use the `max_lenght` paramter to put a limit on the length of text the model can generate in one call."
   ]
  },
  {
   "cell_type": "code",
   "id": "eb3aa00858df05ad",
   "metadata": {},
   "source": [
    "MAX_LENGTH = 30"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "470cbffaa64dbfc0",
   "metadata": {},
   "source": [
    "At the start, the `MY_TEXT` variable gives an initial context to the generated text. We will update this variable with the generated text after each call to the udf, making it add to the text each time.\n",
    "The generated text can be found in the `generated_text` column of the udf-output.\n",
    "\n",
    "You can run the next cell multiple times to see how the text evolves with multiple calls."
   ]
  },
  {
   "cell_type": "code",
   "id": "51b0d826-519a-4e03-9ce0-3827d0756f1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "running_model_pyexasol"
    ]
   },
   "source": [
    "sql = f\"\"\"\n",
    "SELECT {ai_lab_config.db_schema}.TE_TEXT_GENERATION_UDF(\n",
    "    NULL,\n",
    "    '{ai_lab_config.bfs_connection_name}',\n",
    "    '{ai_lab_config.bfs_model_subdir}',\n",
    "    '{MODEL_NAME}',\n",
    "    '{MY_TEXT}',\n",
    "    {MAX_LENGTH},\n",
    "    True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with open_pyexasol_connection(ai_lab_config, compression=True) as conn:\n",
    "    conn.execute(query=activation_sql)\n",
    "    result = conn.export_to_pandas(query_or_table=sql).squeeze()\n",
    "    MY_TEXT = result['GENERATED_TEXT']\n",
    "    # Errors can be observed at result['ERROR_MESSAGE']\n",
    "\n",
    "print(MY_TEXT)\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e1d0ab9bebb94ee",
   "metadata": {},
   "source": [
    " If you need more details to your output, you can find information on all output columns in the <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
