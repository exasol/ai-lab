{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d1ce78-4394-463a-877d-4c87c3d24e8c",
   "metadata": {},
   "source": [
    "# Training Classification Model\n",
    "\n",
    "In this notebook, we will train a very simple classification model for labeling Cherenkov radiation shower images. The images will be classified as those caused by primary gammas (signal) and those initiated by cosmic rays in the upper atmosphere (background). You can find more information about the problem domain <a href=\"https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\" target=\"_blank\" rel=\"noopener\">here</a>.\n",
    "\n",
    "We will train the model in this notebook using <a href=\"https://scikit-learn.org/stable/\" target=\"_blank\" rel=\"noopener\">`scikit-learn`</a>, on the training data we are going to export from the database.\n",
    "\n",
    "To execute queries and load data from the Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the sandbox](../sandbox_config.ipynb).\n",
    "2. [Load the MAGIC Gamma Telescope data](../data/data_telescope.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a59e1-6271-4b07-95ea-9b9e51271bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf64ef4-cbd5-42f5-8f5a-072d4a444c57",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "First, we will export data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ad1b7-231b-471c-aced-51e09b2ea3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exasol.connections import open_pyexasol_connection\n",
    "from stopwatch import Stopwatch\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "with open_pyexasol_connection(sb_config, compression=True) as conn:\n",
    "    df = conn.export_to_pandas(query_or_table=(sb_config.SCHEMA, 'TELESCOPE_TRAIN'))\n",
    "\n",
    "print(f\"Loading the data took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b7cd2-02dd-4aae-9966-6ac0c2f4ad4f",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "The data has no missing values. In order to keep things simple we will be using a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn-tree-decisiontreeclassifier\" target=\"_blank\" rel=\"noopener\">`Decision Tree Classifier`</a> algorithm which requires little in terms of pre-processing for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87411986-57ad-4306-a3ae-5f98a48fcc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train and validation sets. Use all available features columns.\n",
    "X, y = df.drop(columns='CLASS'), df['CLASS']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Create and train the model.\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8dd239-2c3f-4635-ad3a-17cbd2ed40da",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "\n",
    "Let's evaluate the model using the validation set.\n",
    "The results may not look particularly impressive but it's OK. We are aiming for simplicity and clarity, not the best prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412e976-20a8-4215-adc6-299cebdc07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make the predictions on the validation set.\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# Build and display the confusion matrix.\n",
    "cm = confusion_matrix(y_valid, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8087e-b524-4fac-ba08-74c2e067a76e",
   "metadata": {},
   "source": [
    "## Upload model into BucketFS\n",
    "\n",
    "Now, let's upload the model into the BucketFS so that it can be used for making classification in SQL queries. To communicate with BucketFS we will be using the <a href=\"https://exasol.github.io/bucketfs-python/\" target=\"_blank\" rel=\"noopener\">`bucketfs-python`</a> module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd580de-cebc-4fc8-a766-71068f28edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from exasol.connections import open_bucketfs_connection\n",
    "\n",
    "MODEL_FILE = 'telescope_tree_model.pkl'\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Connect to the BucketFS service\n",
    "bucket = open_bucketfs_connection(sb_config)\n",
    "\n",
    "# Serialize the model into a byte-array and upload it to the BucketFS, \n",
    "# where it will be saved in the file with the specified name.\n",
    "bucket.upload(MODEL_FILE, pickle.dumps(model))\n",
    "\n",
    "print(f\"Uploading the model took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af542ef-c9ea-424c-85ad-2813ec769e0a",
   "metadata": {},
   "source": [
    "Now we are ready to use this model in our SQL queries. This will be demonstrated in the [following notebook](sklearn_predict_telescope.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
