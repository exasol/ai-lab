{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50507999-7f6c-4ee2-9d21-657f43dbbee8",
   "metadata": {},
   "source": [
    "# Zero-shot classification model\n",
    "\n",
    "In this notebook we will load and use a zero shot classification language model. Learn about the Zero Shot Classification task <a href=\"https://huggingface.co/tasks/zero-shot-classification\" target=\"_blank\" rel=\"noopener\">here</a>. Please also refer to the Transformer Extension <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a> to find more information about the UDF used in this notebook.\n",
    "\n",
    "We will be running SQL queries using <a href=\"https://jupysql.ploomber.io/en/latest/quick-start.html\" target=\"_blank\" rel=\"noopener\"> JupySQL</a> SQL Magic.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the sandbox](../sandbox_config.ipynb).\n",
    "2. [Initialize the Transformer Extension](te_init.ipynb).\n",
    "\n",
    "## Set up\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701e026-f252-496e-87cb-8b04f46443c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c23f14-f56d-45d9-9b58-4c343a54e46c",
   "metadata": {},
   "source": [
    "Let's bring up JupySQL and connect to the database via SQLAlchemy. Please refer to the documentation of <a href=\"https://github.com/exasol/sqlalchemy-exasol\" target=\"_blank\" rel=\"noopener\">sqlalchemy-exasol</a> for details on how to connect to the database using the Exasol SQLAlchemy driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874261b-9c57-48ef-a4e7-8a47af64fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/jupysql_init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aca6a-5479-41ec-936c-d2cac34b6b11",
   "metadata": {},
   "source": [
    "## Get language model\n",
    "\n",
    "To demonstrate the zero shot classification task we will use the [Cross-Encoder for Natural Language Inference](https://huggingface.co/cross-encoder/nli-deberta-base).\n",
    "\n",
    "We need to load the model from the Huggingface hub into the BucketFS. This could potentially be a long process. Unfortunately, we cannot tell exactly when it has finished. The notebook's hourglass may not be a reliable indicator. BucketFS will still be doing some work when the call issued by the notebook returns. Please wait for a few moments after that, before querying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc473cf7-957b-491c-8925-40e0341ab78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the name of the model at the Huggingface Hub\n",
    "MODEL_NAME = 'cross-encoder/nli-deberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d74058-92c2-48ae-b745-5651e32a419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/model_retrieval.ipynb\n",
    "load_huggingface_model(MODEL_NAME, sb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae22cbe-92c7-44a1-af67-155cf78de7ac",
   "metadata": {},
   "source": [
    "## Use language model\n",
    "\n",
    "Below is a chunk of text that we will try to classify using labels that were not used during the model training. Out of five suggested labels the first two are much more relevant than the others. We expect the model to give them significantly higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81271ed8-b61e-4aeb-ac9b-6a12d72de897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to be classified.\n",
    "MY_TEXT = \"\"\"\n",
    "A new model offers an explanation for how the Galilean satellites formed around the solar system’s largest world. \n",
    "Konstantin Batygin did not set out to solve one of the solar system’s most puzzling mysteries when he went for a\n",
    "run up a hill in Nice, France. Dr. Batygin, a Caltech researcher, best known for his contributions to the search\n",
    "for the solar system’s missing “Planet Nine,” spotted a beer bottle. At a steep, 20 degree grade, he wondered why\n",
    "it wasn’t rolling down the hill. He realized there was a breeze at his back holding the bottle in place. Then he\n",
    "had a thought that would only pop into the mind of a theoretical astrophysicist: “Oh! This is how Europa formed.”\n",
    "Europa is one of Jupiter’s four large Galilean moons. And in a paper published Monday in the Astrophysical Journal,\n",
    "Dr. Batygin and a co-author, Alessandro Morbidelli, a planetary scientist at the Côte d’Azur Observatory in France,\n",
    "present a theory explaining how some moons form around gas giants like Jupiter and Saturn, suggesting that\n",
    "millimeter-sized grains of hail produced during the solar system’s formation became trapped around these massive\n",
    "worlds, taking shape one at a time into the potentially habitable moons we know today.\n",
    "\"\"\"\n",
    "\n",
    "# Make sure our texts can be used in an SQL statement.\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")\n",
    "\n",
    "# Classes, not seen during model training.\n",
    "MY_LABELS = 'space & cosmos, scientific discovery, microbiology, robots, archeology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cabf49-3e4e-4745-bb62-e76e5adeac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH MODEL_OUTPUT AS\n",
    "(\n",
    "    SELECT TE_ZERO_SHOT_TEXT_CLASSIFICATION_UDF(\n",
    "        NULL,\n",
    "        '{{sb_config.TE_BFS_CONN}}',\n",
    "        '{{sb_config.TE_TOKEN_CONN}}',\n",
    "        '{{sb_config.TE_MODELS_BFS_DIR}}',\n",
    "        '{{MODEL_NAME}}',\n",
    "        '{{MY_TEXT}}',\n",
    "        '{{MY_LABELS}}'\n",
    "    )\n",
    ")\n",
    "SELECT label, score, error_message FROM MODEL_OUTPUT ORDER BY SCORE DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16ed3d-e381-4535-afa9-22e18fb64362",
   "metadata": {},
   "source": [
    "The code above shows how the model works on a toy example. However, the main purpose of having a model deployed in the database is to get a quick response for a batch input. The performance gain comes from two factors - localization and parallelization. The first means that the input data never crosses the machine boundaries. The second means that multiple instances of the model are processing the data on all available nodes in parallel.\n",
    "\n",
    "Another advantage of making predictions within the database is the enhanced data security. The task of safeguarding privacy can be simplified giving the fact that the source data never leaves the database machine.\n",
    "\n",
    "In a more practical application the text to be classified would be stored in a column of a database table. For example, if we wanted to get a label with the highest score for each row of the input table `MY_TEXT_TABLE`, where the text in question is in the column `MY_TEXT_COLUMN`, the SQL would look similar to this:\n",
    "```\n",
    "WITH MODEL_OUTPUT AS\n",
    "(\n",
    "    SELECT TE_ZERO_SHOT_TEXT_CLASSIFICATION_UDF(..., MY_TEXT_COLUMN, <MY_LABELS>) FROM MY_TEXT_TABLE\n",
    ")\n",
    "SELECT test_data, label FROM MODEL_OUTPUT WHERE rank=1;\n",
    "```\n",
    "Please note, that the response time observed on the provided example with a single input will not be scaled up linearly in case of multiple inputs. Much of the latency falls on loading the model into the CPU memory from BucketFS. This needs to be done only once regardless of the number of inputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
