{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa128b9-3c22-4f33-85c5-be5d9c5b290f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/exasol/ai-lab/refs/heads/main/assets/Exasol_Logo_2025_Dark.svg\" style=\"width:200px; margin: 10px;\" />\n",
    "</div>\n",
    "\n",
    "# Text classification model\n",
    "\n",
    "In this notebook, we will load and use a text classification language model that can assign a label to a given text. Learn more about the Text Classification task <a href=\"https://huggingface.co/tasks/text-classification\" target=\"_blank\" rel=\"noopener\">here</a>. Please also refer to the Transformer Extension <a href=\"https://github.com/exasol/transformers-extension/blob/main/doc/user_guide/user_guide.md\" target=\"_blank\" rel=\"noopener\">User Guide</a> to find more information about the UDFs used in this notebook.\n",
    "\n",
    "We will be running SQL queries using <a href=\"https://jupysql.ploomber.io/en/latest/quick-start.html\" target=\"_blank\" rel=\"noopener\"> JupySQL</a> SQL Magic.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the AI-Lab](../main_config.ipynb).\n",
    "2. [Initialize the Transformer Extension](te_init.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Open Secure Configuration Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca8f5fb-0fe7-4f07-895d-0857d6c82af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f39d7-26f1-4419-bfa9-a0057a45380f",
   "metadata": {},
   "source": [
    "Let's bring up JupySQL and connect to the database via SQLAlchemy. \n",
    "Please refer to the documentation of [sqlalchemy-exasol](https://github.com/exasol/sqlalchemy-exasol) for details on how to connect to the database using the Exasol SQLAlchemy driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe38507-de1a-417e-81d4-70c956a70914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/jupysql_init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee4351-6210-4266-9525-d35f4381ba30",
   "metadata": {},
   "source": [
    "## Get language model\n",
    "\n",
    "To demonstrate the text classification task we will use the [Ekman emotions classifier](https://huggingface.co/arpanghoshal/EkmanClassifier) model.\n",
    "\n",
    "We need to load the model from the Huggingface hub into the [BucketFS](https://docs.exasol.com/db/latest/database_concepts/bucketfs/bucketfs.htm). This could potentially be a long process. Unfortunately, we cannot tell exactly when it has finished. The notebook's hourglass may not be a reliable indicator. BucketFS will still be doing some work when the call issued by the notebook returns. Please wait for a few moments after that, before querying the model.\n",
    "\n",
    "You might see a warning that some weights are newly initialized and the model should be trained on a down-stream task. Please ignore this warning. For the purpose of this demonstration, it is not important, the model should still be able to produce some meaningful output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ff6db-1bd5-4886-b353-27f3c72db2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exasol.nb_connector.model_installation import install_model, TransformerModel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "# This is the name of the model at the Huggingface Hub\n",
    "MODEL_NAME = 'arpanghoshal/EkmanClassifier'\n",
    "install_model(ai_lab_config, TransformerModel(MODEL_NAME, 'sequence_classification', AutoModelForSequenceClassification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5a2a7-ddab-40b8-aed1-7e6ddaec867a",
   "metadata": {},
   "source": [
    "## Use language model\n",
    "\n",
    "Let's try to classify a single phrase that definitely bears emotions but is also somewhat ambiguous - \"Oh my God!\".\n",
    "We will save the result in the variable `udf_output` to support automatic testing of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9e9b4-d9ce-410b-b374-a7d9f8feccea",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "running_model"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save udf_output\n",
    "WITH MODEL_OUTPUT AS\n",
    "(\n",
    "    SELECT TE_SEQUENCE_CLASSIFICATION_SINGLE_TEXT_UDF(\n",
    "        NULL,\n",
    "        '{{ai_lab_config.bfs_connection_name}}',\n",
    "        '{{ai_lab_config.bfs_model_subdir}}',\n",
    "        '{{MODEL_NAME}}',\n",
    "        'Oh my God!',\n",
    "        'ALL'\n",
    "    )\n",
    ")\n",
    "SELECT label, score, error_message FROM MODEL_OUTPUT  ORDER BY SCORE DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ce1452-2571-447b-94f9-b923e6a2cb75",
   "metadata": {},
   "source": [
    "Now we are going to add some context to our exclamation and use another UDF that takes a pair of sentences. Let's see how it will change the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb66252-36b6-441f-9e7d-bf9ffcb3f8df",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "running_model"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save udf_output\n",
    "WITH MODEL_OUTPUT AS\n",
    "(\n",
    "    SELECT TE_SEQUENCE_CLASSIFICATION_TEXT_PAIR_UDF(\n",
    "        NULL,\n",
    "        '{{ai_lab_config.bfs_connection_name}}',\n",
    "        '{{ai_lab_config.bfs_model_subdir}}',\n",
    "        '{{MODEL_NAME}}',\n",
    "        'Oh my God!',\n",
    "        'I lost my purse.',\n",
    "        'ALL'\n",
    "    )\n",
    ")\n",
    "SELECT label, score, error_message FROM MODEL_OUTPUT ORDER BY SCORE DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f68d93-3cea-4db5-82b9-23a2e3bad9a5",
   "metadata": {},
   "source": [
    "The code above shows how the model works on a toy example. However, the main purpose of having a model deployed in the database is to get a quick response for a batch input. The performance gain comes from two factors - localization and parallelization. The first means that the input data never crosses the machine boundaries. The second means that multiple instances of the model are processing the data on all available nodes in parallel.\n",
    "\n",
    "Another advantage of making predictions within the database is enhanced data security. The task of safeguarding privacy can be simplified given the fact that the source data never leaves the database machine.\n",
    "\n",
    "In a more practical application, the text to be classified would be stored in a column of a database table. For example, if we wanted to get a label with the highest score for each row of the input table `MY_TEXT_TABLE`, where the text in question is in the column `MY_TEXT_COLUMN`, the SQL would look similar to this:\n",
    "```\n",
    "SELECT TE_SEQUENCE_CLASSIFICATION_SINGLE_TEXT_UDF(..., MY_TEXT_COLUMN) FROM MY_TEXT_TABLE;\n",
    "```\n",
    "Please note, that the response time observed on the provided example with a single input will not be scaled up linearly in case of multiple inputs. Much of the latency falls on loading the model into the CPU memory from BucketFS. This needs to be done only once regardless of the number of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad81a7f-f0ca-4473-a4ba-25349313f5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
