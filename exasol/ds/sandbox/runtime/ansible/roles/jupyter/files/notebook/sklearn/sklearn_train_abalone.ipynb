{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289d2a8c-953d-46e5-8c73-ad810c29b20f",
   "metadata": {},
   "source": [
    "# Training Regression Model\n",
    "\n",
    "In this notebook, we will train a simple regression model for predicting the age of an abalone from its physical measurements and sex.You can find more information about the problem domain <a href=\"https://archive.ics.uci.edu/dataset/1/abalone\" target=\"_blank\" rel=\"noopener\">here</a>.\n",
    "\n",
    "We will train the model in this notebook using <a href=\"https://scikit-learn.org/stable/\" target=\"_blank\" rel=\"noopener\">`scikit-learn`</a>, on the training data we are going to export from the database.\n",
    "\n",
    "To execute queries and load data from the Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following steps need to be completed:\n",
    "1. [Configure the sandbox](../sandbox_config.ipynb).\n",
    "2. [Load the Abalone data](../data/data_abalone.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Access configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c628f-853e-4850-8bab-46f7f645856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089a9b5-89b1-45a9-925d-521945ae89b7",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "First, we will export data into a pandas DataFrame and split it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be5d5a-ebcc-4fb4-829f-29a5442579d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exasol.connections import open_pyexasol_connection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stopwatch import Stopwatch\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "with open_pyexasol_connection(sb_config, compression=True) as conn:\n",
    "    df = conn.export_to_pandas(query_or_table=(sb_config.SCHEMA, 'ABALONE_TRAIN'))\n",
    "\n",
    "X, y = df.drop(columns='RINGS'), df['RINGS']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"Loading the data took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e36c7-06aa-4c2f-bf46-10b328cee623",
   "metadata": {},
   "source": [
    "## Analyze data\n",
    "\n",
    "Let's look at the features. We will first check what physical measurements have predictive power. For that, we will compute mutual information between the measurements' input columns and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3e231-b8fe-4498-9393-f65ecbac618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "X_meas = X_train.drop(columns='SEX')\n",
    "mi = mutual_info_regression(X_meas, y_train)\n",
    "dict(zip(X_meas.columns, mi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb025ff-64e3-4118-8313-039da78f6a3c",
   "metadata": {},
   "source": [
    "Now let's see if SEX is a good predictor. We will do the ANOVA test and print the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e9d98-888e-473c-8d7a-1f304364b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "f_classif(y_train.to_frame(), X_train['SEX'])[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3cac4-8b4d-4423-8e7b-2ded0e8c77e8",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Let's make a pipeline. We will use all features in the input. We will do One Hot Encoding of the SEX column and normalize all others, including the target. Let's use the Support Vector Machine as the regression model. We will drop the column names in the inputs, as they will not be available in the prediction UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb0d95-81f8-4b93-8012-a3f39ac37f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create the pipeline.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), [1, 2, 3, 4, 5, 6, 7]),\n",
    "        (\"cat\", OneHotEncoder(), [0]),\n",
    "    ]\n",
    ")\n",
    "regressor = SVR(kernel='rbf')\n",
    "model = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), ('regressor', regressor)]\n",
    ")\n",
    "model = TransformedTargetRegressor(regressor=model, transformer=StandardScaler())\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Train the model.\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "print(f\"Training of the model took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81bf25-ef8c-4e2d-9c1b-1ef9e1cbed20",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "\n",
    "Let's see what prediction performance we've got, printing some regression metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061744b4-c401-4b79-914f-d3d3ba3aad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_valid.values)\n",
    "\n",
    "print('Mean absolute error:', mean_absolute_error(y_valid, y_pred))\n",
    "print('Mean squared error:', mean_squared_error(y_valid, y_pred))\n",
    "print('Explained variance:', explained_variance_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6fd07e-5175-4767-a5d0-339d42afa135",
   "metadata": {},
   "source": [
    "## Upload model into BucketFS\n",
    "\n",
    "Now, let's upload the model into the BucketFS so that it can be used for making predictions in SQL queries. To communicate with BucketFS we will be using the <a href=\"https://exasol.github.io/bucketfs-python/\" target=\"_blank\" rel=\"noopener\">`bucketfs-python`</a> module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61810f9-3d9e-4e1a-aca3-81cf976540d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from exasol.connections import open_bucketfs_connection\n",
    "\n",
    "MODEL_FILE = 'abalone_svm_model.pkl'\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Connect to the BucketFS service\n",
    "bucket = open_bucketfs_connection(sb_config)\n",
    "\n",
    "# Serialize the model into a byte-array and upload it to the BucketFS, \n",
    "# where it will be saved in the file with the specified name.\n",
    "bucket.upload(MODEL_FILE, pickle.dumps(model))\n",
    "\n",
    "print(f\"Uploading the model took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edb448-40b9-4e6a-9d32-4a499334c467",
   "metadata": {},
   "source": [
    "Now we are ready to use this model in our SQL queries. This will be demonstrated in the [following notebook](sklearn_predict_abalone.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7be224-1cd9-436f-963b-0443f2003a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
