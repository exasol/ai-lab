{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c96906-407d-4c43-bfeb-4ff38644e198",
   "metadata": {},
   "source": [
    "# Data Analysis with Text AI\n",
    "\n",
    "In this notebook, we will do some basic analysis on the semantic data extracted from the Customer Support Tickets.\n",
    "\n",
    "We will be running SQL queries using both the <a href=\"https://jupysql.ploomber.io/en/latest/quick-start.html\" target=\"_blank\" rel=\"noopener\"> JupySQL</a> SQL Magic\n",
    "and the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a>.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook the following step needs to be completed:\n",
    "1. [Run Text AI Preprocessing](txaie_preprocessing.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Open Secure Configuration Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139322dc-7524-4970-8a71-3a2104293852",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addea207-4fa2-4227-ba94-642da791523d",
   "metadata": {},
   "source": [
    "### Initialise JupySQL\n",
    "Let's bring up JupySQL and connect to the database via SQLAlchemy. Please refer to the documentation of <a href=\"https://github.com/exasol/sqlalchemy-exasol\" target=\"_blank\" rel=\"noopener\">sqlalchemy-exasol</a> for details on how to connect to the database using the Exasol SQLAlchemy driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62b107-b107-42b8-94f1-609eb6ff38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/jupysql_init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baddae9-3455-4dc6-a446-8cb0bce42c4f",
   "metadata": {},
   "source": [
    "### Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d3568d-58c5-4ed2-84cd-713c4332309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ipywidgets import Dropdown\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from exasol.nb_connector.connections import open_pyexasol_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0691199-c446-498e-97bc-bb0018078346",
   "metadata": {},
   "source": [
    "## Urgent vs Non-urgent tieckts\n",
    "\n",
    "### Create `TICKET_URGENCY` view\n",
    "\n",
    "First, let us create a view that adds the `IS_URGENT` flag to each document. For this, we can use the results of the topic classifier. We have run the classifier using two topics - \"urgent\" and \"not urgent\". The output of the classifier is the cross product of the documents (tickets) and topics. For our purpose we can select the rows with the \"urgent\" topic.\n",
    "\n",
    "For each document, the classifier sets the rank and the score of every topic. We do not want to rely purely on the rank, because it does not indicate certainty of the classification. Instead we will use the score which is akin a probability of the document belonging to the given topic (assuming the topics are mutually exclusive). We will deem the ticket as urgent if its \"urgent\" topic score is greater than 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974d35d-b737-4fa9-b772-851ac2081cdd",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW TICKET_URGENCY AS\n",
    "SELECT \n",
    "    D.*,\n",
    "    T.TOPIC_SCORE,\n",
    "    T.TOPIC_SCORE > 0.7 AS IS_URGENT\n",
    "FROM DOCUMENTS_AI_LAB_CUSTOMER_SUPPORT_TICKETS_VIEW_VIEW D\n",
    "JOIN TOPICS_VIEW T ON \n",
    "    D.TEXT_DOC_ID=T.TEXT_DOC_ID AND \n",
    "    D.TEXT_CHAR_BEGIN=T.TEXT_CHAR_BEGIN AND\n",
    "    D.TEXT_CHAR_END=T.TEXT_CHAR_END\n",
    "WHERE T.TOPIC='urgent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6860ee7-ccf8-43df-95a0-7c573580f337",
   "metadata": {},
   "source": [
    "Now we can inspect the urgent tickets. \n",
    "\n",
    "**Note**: We will often see tickets that contain phrases, like \"I need them urgently\", or \"but the issue remains unresolved\". These prhases indicate for the model a higher urgency of a ticket. However, this might only reflect the urgency for the author of the ticket and are soley based on the content of ticket description. The extracted urgency might not reflect your internal work priority for tickets. Also, for the classification of the ticket priority, factors that are external to the text might need to be considered. The model here can only consider the information conveyed by the text which might be able to give input for the final classification of the ticket priority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277caff-3036-4779-b5c0-c18e5377f286",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TICKET_ID, CUSTOMER_NAME, DATE_OF_PURCHASE, TICKET_DESCRIPTION, TOPIC_SCORE\n",
    "FROM TICKET_URGENCY\n",
    "WHERE IS_URGENT = TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f7844c-a448-44c5-becd-e4529f5975e2",
   "metadata": {},
   "source": [
    "### Count urgent and non-urgent tickets\n",
    "\n",
    "Here we will display the total number of urgent and non-urgent tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef993ba-af58-4a7c-b008-0e99b616dac7",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT 'Urgent' as URGENCY, SUM(IS_URGENT) AS CNT\n",
    "FROM TICKET_URGENCY\n",
    "UNION\n",
    "SELECT 'Not Urgent' as URGENCY, SUM(1 - IS_URGENT) AS CNT\n",
    "FROM TICKET_URGENCY\n",
    "ORDER BY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca5453-3401-4233-b756-fb90da37eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlplot pie --table URGENT_TICKET_COUNT --column URGENCY CNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7f626-a66e-4c81-a431-c4f66ebb5d20",
   "metadata": {},
   "source": [
    "## Products with urgent tickets\n",
    "\n",
    "In this section we will take a look at which products have the biggest number of urgent tickets.\n",
    "\n",
    "### Inspecting the Products\n",
    "\n",
    "Let us first inspect the products that were extracted from the tickets\n",
    "\n",
    "We will use the results of the named entity extractor. The products are entities where the `entity_type` looks like \"product_xxx\". Note, that the extractor also provides the positions of entities in the text, which we don't need here. We shall account for the fact that there are potentially multiple instances of the same entity in a document.                                                                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8886e2-2e27-47c3-ac01-2aa08307dd47",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT E.ENTITY as PRODUCT, COUNT(DISTINCT D.TICKET_ID) as TICKET_COUNT\n",
    "FROM DOCUMENTS_AI_LAB_CUSTOMER_SUPPORT_TICKETS_VIEW_VIEW D\n",
    "JOIN NAMED_ENTITY_VIEW E ON \n",
    "    D.TEXT_DOC_ID=E.TEXT_DOC_ID AND \n",
    "    D.TEXT_CHAR_BEGIN=E.TEXT_CHAR_BEGIN AND\n",
    "    D.TEXT_CHAR_END=E.TEXT_CHAR_END\n",
    "WHERE E.ENTITY_TYPE like 'product%'\n",
    "GROUP BY E.ENTITY\n",
    "ORDER BY TICKET_COUNT DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc1c83-b36e-4819-ab34-b01c2f8e7560",
   "metadata": {},
   "source": [
    "Now lets show the products in a word cloud. The font size of the product is larger for products that occur in more tickets. The colors in the word cloud are choosen to easier distingish different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f85a0-754c-4150-b0f2-6953b5a995b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_with_ticket_count_df = products_with_ticket_count.DataFrame()\n",
    "products_with_ticket_count_dict = products_with_ticket_count_df.set_index(\"product\")[\"ticket_count\"].to_dict()\n",
    "wordcloud = WordCloud(background_color=\"white\").generate_from_frequencies(products_with_ticket_count_dict)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a01961-a559-4723-857c-2fdc9278bf81",
   "metadata": {},
   "source": [
    "### Create `PRODUCT_ATTENTION` view\n",
    "\n",
    "From this point onward we will be looking at a limited number of products with the biggest number of urgent tickets. Let us first create a view `URGENT_PRODUCT_CO_OCCURRENCE` that selects products that are contained inside extracted topic with the label `urgent`.\n",
    "\n",
    "To create `URGENT_PRODUCT_CO_OCCURRENCE` view we are using the `CO_OCCURRENCE` view which is created by the `StandardExtractor`. The `CO_OCCURRENCE` view joins topics, named entities and keywords in the same document together and provides addtional columns to define the positional relations between them, such as the distance between an named entity and a keyword. However, for the moment we don not need these relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc4568-3af6-4ea1-81b9-209c02b8eb8c",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW URGENT_PRODUCT_CO_OCCURRENCE AS\n",
    "SELECT *\n",
    "FROM CO_OCCURRENCE COO\n",
    "WHERE TOPIC = 'urgent'\n",
    "AND ENTITY_TYPE like 'product%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32010f-9b9c-4114-a5eb-627fa1a4509a",
   "metadata": {},
   "source": [
    "Now we can create a view `PRODUCT_ATTENTION` on top of `URGENT_PRODUCT_CO_OCCURRENCE`, that selects the ten products with the most urgent tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23cf56-0fd9-4b86-a976-1085a4b2c0de",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW PRODUCT_ATTENTION AS\n",
    "SELECT COO.ENTITY AS PRODUCT, COUNT(DISTINCT D.TICKET_ID) as URGENT_TICKETS\n",
    "FROM URGENT_PRODUCT_CO_OCCURRENCE COO\n",
    "JOIN DOCUMENTS_AI_LAB_CUSTOMER_SUPPORT_TICKETS_VIEW_VIEW AS D\n",
    "ON D.text_doc_id = COO.text_doc_id\n",
    "WHERE COO.TOPIC_SCORE > 0.7\n",
    "GROUP BY local.PRODUCT\n",
    "ORDER BY local.URGENT_TICKETS DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba444f-e500-4810-8eb4-672ccdc80783",
   "metadata": {},
   "source": [
    "### Show the number of tickets for the selected products\n",
    "\n",
    "Here we will look at the number of urgent and non-urgent tickets for each of the selected products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31aba70-377c-4bad-9229-492e6e1d07c9",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql7"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW TICKET_URGENCY_FOR_PRODUCTS_UNDER_ATTENTION AS\n",
    "SELECT DISTINCT TICKET_ID, ENTITY AS PRODUCT, TOPIC_SCORE > 0.7 as IS_URGENT\n",
    "FROM URGENT_PRODUCT_CO_OCCURRENCE COO\n",
    "JOIN DOCUMENTS_AI_LAB_CUSTOMER_SUPPORT_TICKETS_VIEW_VIEW AS D\n",
    "ON D.text_doc_id = COO.text_doc_id\n",
    "JOIN PRODUCT_ATTENTION A \n",
    "ON COO.ENTITY=A.PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac6c8b-bfc6-45d5-97d1-1cd54e230525",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql8"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT PRODUCT, SUM(IS_URGENT) as IS_URGENT\n",
    "FROM TICKET_URGENCY_FOR_PRODUCTS_UNDER_ATTENTION\n",
    "GROUP BY PRODUCT\n",
    "ORDER BY IS_URGENT DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5ac7b-4687-4a8b-bcb3-d734fcf8a942",
   "metadata": {},
   "source": [
    "Now let us compute the percentage of urgent and non-urgent tickets for each of the selected products and plot it as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b62f44-d166-43e9-a0a0-7bf7259549f1",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql9"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT PRODUCT, SUM(1-IS_URGENT)/COUNT(1)*100 as IS_NOT_URGENT, SUM(IS_URGENT)/COUNT(1)*100 as IS_URGENT\n",
    "FROM TICKET_URGENCY_FOR_PRODUCTS_UNDER_ATTENTION\n",
    "GROUP BY PRODUCT\n",
    "ORDER BY IS_URGENT ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281f5ed-19aa-40f4-8181-82d4796787dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precent_of_urgent_tickets_per_product.DataFrame().set_index(\"product\").plot(kind='barh', stacked=True, xlabel=\"percent of tickets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6521b6f-e36d-4a36-80bb-fa4b77369b7f",
   "metadata": {},
   "source": [
    "## Reasons behind tickets\n",
    "\n",
    "In this section we will try to look at common reasons for raising a ticket, in a scope of a particular product. The reasons or clues, as it might be a better term, are represented by keywords. \n",
    "\n",
    "First we will load out selected products into a dropdown box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8efb9-432c-4f54-bc6b-53d19cf6f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT PRODUCT\n",
    "FROM PRODUCT_ATTENTION\n",
    "ORDER BY URGENT_TICKETS DESC\n",
    "\"\"\"\n",
    "\n",
    "with open_pyexasol_connection(ai_lab_config, compression=True, schema=ai_lab_config.db_schema) as connection:\n",
    "    options = connection.execute(query=query).fetchcol()\n",
    "\n",
    "dropdown = Dropdown(\n",
    "    options=options,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2bef2-0af4-497f-b83a-6e6771b31bcd",
   "metadata": {},
   "source": [
    "### View keywords in a Word Cloud\n",
    "\n",
    "We will compute frequencies of the keywords in the tickets for the selected product. There are few keywords we would want to exclude. Firstly, this is the name of the product or any part of the name. Then we also want to exclude some common words which, unfortunately are often identified as keywords. Below is the list of such common words. It can be extended as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f95af6-c7e6-4bbd-85da-2748c910133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_keywords = \"('product', 'issue')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac1f22-7f8c-477f-bfd2-987cbb01bf21",
   "metadata": {},
   "source": [
    "Now we are ready to compute and display the keyword frequencies. \n",
    "\n",
    "We will use the sum of the keyword scores as a proxy for the frequency. The score is akin a probability that the word is actually a keyword. So, the sum of the scores can be interpreted as an expectation of the total number of occurrences of the given keyword in the collection of tickets for the selected product.\n",
    "                                                                                                                                                            Note, that the keyword extractor output includes the positions of keywords in the text. These positions themselves are not required for our analysis. However, the implication is that a document may have multiple instances of the same keyword. For the sake of simplicity, we compute the frequency not limiting the number of occurrences of a keyword in a single document to one.                                                                                                                               \n",
    "We will reuse our `URGENT_PRODUCT_CO_OCCURRENCE` view from before. We only add addtional conditions and aggregate the data as described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2cf97-0da9-4f9d-a648-f2f2526d16f2",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql10"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    COO.ENTITY as PRODUCT,\n",
    "    COO.KEYWORD,\n",
    "    SUM(COO.KEYWORD_SCORE) AS SCORE\n",
    "FROM URGENT_PRODUCT_CO_OCCURRENCE COO\n",
    "WHERE COO.ENTITY='{{dropdown.value}}'\n",
    "AND INSTR('{{dropdown.value.strip().upper()}}', UCASE(COO.KEYWORD)) = 0\n",
    "AND COO.KEYWORD NOT IN {{exclude_keywords}}\n",
    "GROUP BY COO.ENTITY, COO.KEYWORD\n",
    "ORDER BY SCORE DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4a01e-e956-4da0-9f20-d3e4cfba8238",
   "metadata": {},
   "source": [
    "We will plot the the keywords in a word cloud. The font-size will be larger for keywords that have a higher sum of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a10740-5ab5-4f00-9c38-ad7639f2ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_with_scores = product_keywords_with_scores.DataFrame()[[\"keyword\", \"score\"]]\n",
    "keywords_with_scores_dict = keywords_with_scores.set_index(\"keyword\")[\"score\"].to_dict()\n",
    "wordcloud = WordCloud(background_color=\"white\").generate_from_frequencies(keywords_with_scores_dict)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
