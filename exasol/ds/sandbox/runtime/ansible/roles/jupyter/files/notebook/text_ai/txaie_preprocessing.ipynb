{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348c85d1b34a6511",
   "metadata": {},
   "source": [
    "# Text AI Preprocessing\n",
    "\n",
    "\n",
    "Here we will demonstrate how the Text AI can be used to build a data-preprocessing workflow. We will be taking a dataset of customer support tickets. This dataset contains unstructured data in the form of ticket descriptions. We will sort these tickets into \"urgent\" and \"not urgent\" cases, and find important named entities and keywords within the text. This will be archived using a Text AI Workflow.\n",
    "\n",
    "We will also demonstrate the Text AI ability to determine if data was already processed, and skip it if applicable.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook one needs to complete the following steps:\n",
    "\n",
    "1. [Load the Customer Support Ticket Dataset](../data/data_customer_support.ipynb)\n",
    "2. [Initialize the Text AI Extension](txaie_init.ipynb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c624589a-697a-4ba0-a9bb-1439bc52c464",
   "metadata": {},
   "source": [
    "## Natural Language Processing Introduction\n",
    "\n",
    "This section contains a short introduction to Natural Language Processing, and the precesses we will use in this notebook.\n",
    "\n",
    "### NLP\n",
    "\n",
    "Natural Language Processing, or the processing of so-called \"unstructured data\" or \"free text\", is the processing(i.e. classification, retrieving of information) of unannotated language.\n",
    "\n",
    "There are tasks in Natural Language Processing (NLP) which seem easy to us humans, but are very hard for a machine to do. For example, inferring the opinion the speaker has about a topic (Opinion Extraction/Mining). Doing these tasks on un-annotated text is even harder. Therefore, multiple ways to annotate a natural language text with additional information were developed. These annotated texts are then better suited for higher-level NLP tasks.\n",
    "                                                                                                                                                   \n",
    "Depending on the amount of data/text which should be processed, annotating by hand is mostly not an option these days, since with increasing dataset sizes the resources needed quickly become unrealistic. Therefore, Exasol Text AI provides you with tools you can use for annotating your data in various ways.\n",
    "                                                                                                                     \n",
    "In this Notebook, we will show you our three default preprocessing workflow steps. Of course, it is possible for you to define your own workflow later on.\n",
    "Let's explain these three steps before we dive into how to run the preprocessing.\n",
    "                                                                                                                     \n",
    "### Topic Classification\n",
    "                                                                                                                     \n",
    "Topic Classification is the task of assigning topics to text/documents/datapoints. In Topic Classification, a given set of topics is used, and each data point is assigned a relevance score and rank for each of the topics. These relevance scores and ranks can then be used to select the best matching topic for each data point.\n",
    "Given that a document is about a particular topic, particular words are expected to appear in the document more or less frequently. However, it is not required for the exact words to describe the topic to be found in a text. This means that topics can be inferred, even if their name/description/topic synonyms are not found in the data.\n",
    "\n",
    "![diagramm a document text added topics](images/topics.drawio.png)\n",
    "Topic Classification works with a given set of these topics as input and assigns to each a relevance score that the text being about this topic. It is usually trained using supervised learning. It can also be used with Zero-Shot Classification models, which can assign classes/topics which have not been seen during the training. This is opposed to other approaches like topic extraction, which is often unsupervised and does not need a list of topics as input, instead extracting them from the data itself.\n",
    "                                                                                                                     \n",
    "### Keyword Search\n",
    "                                                                               \n",
    "Keyword Search is about identifying the most relevant words or phrases(Keywords/Keyphrases) from a given text.\n",
    "These can then help in further steps, e.g. summarizing the content of texts and recognizing the main topics discussed.\n",
    "Keywords or phrases need be present in the text.\n",
    "For Example:\n",
    "![diagramm a document text with highlighted keywords](images/keywords.drawio.png)\n",
    "\n",
    "\n",
    "### Named Entity Recognition\n",
    "\n",
    "Named entity recognition (NER) is about locating and classify so called \"named entities\" mentioned in a text document. Depending on the model, entities are e.g. person names, organizations, locations, or vehicles etc., so \"things that have names\". The model seeks out those entities, returning their positions in the document, as well as their class.\n",
    "\n",
    "### Example Result of 3 Steps\n",
    "\n",
    "Let's look at an example of what the output for these three steps might look like combined. For a given document, consider the document content to be \"I'm having an issue with the GoPro Hero. It's affecting my productivity.\". We may use a topic classifier with the input topic set of \"urgent, not urgent\" for inferring urgency from ticket content. The NER and Keyword Search do not need additional input, they just work with the document itself. Then the output of a preprocessing pipeline containing all three steps could look something like this:\n",
    "\n",
    "![diagramm showing document text with found entity and keyword and topic](images/document_annotated.drawio.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed253c4f",
   "metadata": {},
   "source": [
    "You can verify if the dataset is already available with the query below. It should return `3606`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c76eaa-867f-40cf-ab4c-b5fa0c918015",
   "metadata": {},
   "source": [
    "## General Setup\n",
    "\n",
    "As a first step, we need to get access to the Ai-Lab secret store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54949e00-bf07-450a-83da-6be3333570f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/access_store_ui.ipynb\n",
    "display(get_access_store_ui('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e69b032-78af-4e83-a397-f77f8e0e6a76",
   "metadata": {},
   "source": [
    "Then we can get the activation SQL for our previously installed Script Language Containers. This will be used to activate those SLCs in order to use their UDFs.\n",
    "\n",
    "We also want to import some of the Python functions of the Text AI and Notebook Connector modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a787606978778e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exasol.nb_connector.connections import open_pyexasol_connection\n",
    "from exasol.nb_connector.text_ai_extension_wrapper import Extraction\n",
    "from exasol.ai.text.extraction.abstract_extraction import Defaults, Output\n",
    "from exasol.ai.text.extractors.standard_extractor import StandardExtractor\n",
    "from exasol.ai.text.extractors.extractor import PipelineExtractor\n",
    "from exasol.ai.text.extractors.source_table_extractor import SourceTableExtractor, SchemaSource, TableSource, NameSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8734bdcd5210f",
   "metadata": {},
   "source": [
    "The next call will make it possible to run SQL directly in this notebook, in order to easier display the results of our preprocessing. The one below sets the maximum number of columns our SQL statements can display in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbab964ee1b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/jupysql_init.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f54b13d5f0ffd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.displaylimit = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa993ed130b0bd",
   "metadata": {},
   "source": [
    "## Create an Example Data Source\n",
    "\n",
    "We will be using a dataset which holds information on customer support tickets. For loading the dataset, please refer to the [prerequisites](#prerequisites). We will split this data into 2 sets, in order to demonstrate how the preprocessing tasks handle new data being added to a data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10afada75565b4f",
   "metadata": {},
   "source": [
    "You can verify if the dataset is already available with the query below. It should return `3606`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed97899",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column=\"TICKET_DESCRIPTION\"\n",
    "key_column=\"TICKET_ID\"\n",
    "table=\"CUSTOMER_SUPPORT_TICKETS\"\n",
    "schema=ai_lab_config.db_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a998c5-a5c0-45bd-be10-73c542569a76",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM \"{{schema}}\".\"{{table}}\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2a0d7-3f0f-4b9d-b1e1-c99dd92ff25c",
   "metadata": {},
   "source": [
    "### Create a View on the Data\n",
    "\n",
    "This dataset has ~3600 entries. You could run the preprocessing for the whole dataset, but it would take quite some time. Instead, we will create a view containing only a part of the dataset, and use this view as the base for our preprocessing.\n",
    "We set the size of this view here. If you want to see how the AI-Lab handles bigger datasets on your Exasol instance, you can set the `view_size` higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a68f5-2adb-4e4b-ac6e-2ecd6c1e722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view=\"TICKETS_SAMPLE\"\n",
    "view_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4829de6-9e25-43c9-a939-6591c28487e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW \"{{schema}}\".\"{{view}}\" AS \n",
    "SELECT * FROM \"{{schema}}\".\"{{table}}\" \n",
    "ORDER BY \"TICKET_ID\" \n",
    "LIMIT {{view_size}};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488ffe2755f950c",
   "metadata": {},
   "source": [
    "Lets check the size of our created view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4300819-e6d3-47cd-8675-8be76c7315b4",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM \"{{schema}}\".\"{{view}}\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3aff79-6dbe-4e4d-a8cc-d4dfcc81753a",
   "metadata": {},
   "source": [
    "As you can see, we now have only our defined 10 data points in the view.\n",
    "\n",
    "Let's now see what our data contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd525e0-017b-4f85-bbbe-577d0e41fdd9",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESC \"{{schema}}\".\"{{view}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c9398-ed8a-4b9c-a801-5d134e1ab7ec",
   "metadata": {},
   "source": [
    "We can see a ticket ID column, as well as some columns containing information about the customer, like name. There are columns containing some metadata for the ticket itself, such as the purchase date, ticket status and ticket channel. The ticket description contains the actual text of the ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd64191-191c-43bf-b58f-4f8fa74a2e48",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    TICKET_ID,\n",
    "    CUSTOMER_NAME,\n",
    "    DATE_OF_PURCHASE,\n",
    "    TICKET_SUBJECT, \n",
    "    TICKET_DESCRIPTION,\n",
    "    TICKET_STATUS,\n",
    "    TICKET_CHANNEL\n",
    "FROM \"{{schema}}\".\"{{view}}\"\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668de46e",
   "metadata": {},
   "source": [
    "### Cleaning up Results of previous Runs of the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84059b2",
   "metadata": {},
   "source": [
    "To make sure the tables the preprocessing will use don't already exist, for example from a previous run of this notebook, we are going to drop them.\n",
    "First, we define a list of tables to drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of tables which the steps below create automatically. If you run the notebook multiple times they need to be dropped in between.\n",
    "table_list = [\n",
    "    \"TXAIE_AUDIT_LOG\",\n",
    "    \"DOCUMENTS\",\n",
    "    f\"DOCUMENTS_{schema}_TICKETS_SAMPLE\",\n",
    "    \"NAMED_ENTITY\",\n",
    "    \"NAMED_ENTITY_LOOKUP_ENTITY_TYPE\",\n",
    "    \"NAMED_ENTITY_LOOKUP_SETUP\",\n",
    "    \"KEYWORD_SEARCH\",\n",
    "    \"KEYWORD_SEARCH_LOOKUP_KEYWORD\",\n",
    "    \"KEYWORD_SEARCH_LOOKUP_SETUP\",\n",
    "    \"TOPIC_CLASSIFIER\",\n",
    "    \"TOPIC_CLASSIFIER_LOOKUP_TOPIC\",\n",
    "    \"TOPIC_CLASSIFIER_LOOKUP_SETUP\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49508a9a",
   "metadata": {},
   "source": [
    "If you are curious about which tables are generated and how they look, you can find that information in the [Results](#results) section below.\n",
    "Next, define a function which drops these tables. Then we call the function.\n",
    "\n",
    "**Note:** If you run into technical issues during the running of this notebook, you might want to run the `delete_text_ai_preprocessing_tables` function again, in order to re-run the workflow from scratch. This will ensure all data gets processed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc96547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_text_ai_preprocessing_tables():\n",
    "    with open_pyexasol_connection(ai_lab_config, compression=True) as conn:\n",
    "        for drop_table in table_list:\n",
    "            conn.execute(f\"\"\"DROP TABLE IF EXISTS \"{schema}\".\"{drop_table}\" \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591623d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_text_ai_preprocessing_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223947757258424",
   "metadata": {},
   "source": [
    "## Download NLP Models\n",
    "\n",
    "We will use multiple different open source Hugging Face Transformers models to run our preprocessing with. \n",
    "* For Named Entity Extraction: [guishe/nuner-v2_fewnerd_fine_super](https://huggingface.co/guishe/nuner-v2_fewnerd_fine_super)\n",
    "* For Topic Classification: [tasksource/ModernBERT-base-nli](https://huggingface.co/tasksource/ModernBERT-base-nli)\n",
    "* For Keyword Extraction: [answerdotai/ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base)\n",
    "\n",
    "These models were already installed during the [intialization](txaie_init.ipynb) of Text AI.\n",
    "\n",
    "You can download your own models as follows:\n",
    "\n",
    "```python\n",
    "from exasol.nb_connector.text_ai_extension_wrapper \n",
    "import install_model, TransformerModel\n",
    "\n",
    "install_model(conf,TransformerModel(\n",
    "    \"your keyword search model\", \n",
    "    \"feature-extraction\", AutoModel))\n",
    "install_model(conf,TransformerModel(\n",
    "    \"your named entity model\", \n",
    "    \"token-classification\", AutoModelForTokenClassification))\n",
    "install_model(conf,TransformerModel(\n",
    "    \"your zero-shot classification model\",\n",
    "    \"zero-shot-classification\", AutoModelForSequenceClassification))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e177878abf872c",
   "metadata": {},
   "source": [
    "## Configure the Text AI Workflow\n",
    "\n",
    "The Text-AI-Extension allows you to configure a data processing workflow. In this Notebook we will be using a basic example where the workflow is defined by a so called `StandardExtractor`.                                                                                                                    \n",
    "#### Configure Default Values\n",
    "\n",
    "Here, we will configure how our workflow should run. In general, each NLP extractor has its own configuration parameters. The `Defaults` object is a helper object allowing us to set these parameters once and apply these settings to all extractors.\n",
    "\n",
    "How you need to set these defaults will depend on your Database. This demonstration should work on a rather small Docker-DB. Therefore, we set the `batch_size` to only 10, so only 10 rows will be processed at once in each UDF instance, and also our `parallelism_per_node` is set to the low value of 1. `parallelism_per_node` determines how many parallel UDF instances are run on each node of your database. If you have a bigger Database to run this Notebook on, you can try to increase both values.\n",
    "The model repository is a data object pointing to the location of the model files we during the extension initailization or the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29932f32-120c-4912-af1b-1d135a609fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = Defaults(\n",
    "    parallelism_per_node=1,\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662afd53-5911-4fbd-b311-f41e95f8ca69",
   "metadata": {},
   "source": [
    "### Define the Extractor\n",
    "\n",
    "Now we need to define an extractor to run our extraction/preprocessing. We will use a `StandardExtractor` which has 3 standard preprocessing steps built-in, namely the topic classification, keyword search and named entity recognition. It is possible to disable each of these steps in the `StandartExtractor` by setting its model to `None`. You can also use a different model instead of the built-in one, by setting its model to a specific HuggingFace model. But here we will use the `StandartExtractor` as is.\n",
    "\n",
    "For the topic classification model we will use the topics \"urgent\", and \"not urgent\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7efc8fc-190f-477b-85ed-d87327b8b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics={\"urgent\", \"not urgent\"}\n",
    "\n",
    "std_extractor =  StandardExtractor(\n",
    "                        # If you want to disable a step, set it to None:\n",
    "                        # named_entity_recognition_model = None,\n",
    "                        # topic_classification_model = None,\n",
    "                        \n",
    "                        # If you want to use a different(not default) model, set its name:\n",
    "                        # keyword_search_model = HuggingFaceModel(name=\"MY_KEYWORD_SEARCH_MODEL\"),\n",
    "                        topics=topics\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef689bb-fb60-480a-a88c-da6e4913c20c",
   "metadata": {},
   "source": [
    "We will also need a `SourceTableExtractor`, which holds information on which data we want to use as a source for our preprocessing, and feed it to the `StandardExtractor`.\n",
    "We give it our schema and view as a data source, and tell it to run the preprocessing on the column `TICKET_DESCRIPTION`, since that is where the Natural Text part of our data is. We also tell it to use the `TICKET_ID` column as an id/key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3f13152-2333-4a11-b57b-8c1daf84c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column=\"TICKET_DESCRIPTION\"\n",
    "key_column=\"TICKET_ID\"\n",
    "\n",
    "src_extractor = SourceTableExtractor(\n",
    "                        name='DOCUMENTS',\n",
    "                        sources=[\n",
    "                            SchemaSource(\n",
    "                                db_schema=NameSelector(pattern=schema),\n",
    "                                tables=[\n",
    "                                    TableSource(\n",
    "                                        table=NameSelector(pattern=view),\n",
    "                                        columns=[NameSelector(pattern=text_column)],\n",
    "                                        keys=[NameSelector(pattern=key_column)]\n",
    "                                    )\n",
    "                                ]\n",
    "                            )\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9b9526-be69-4bdc-8ee7-51a59eaf7b9e",
   "metadata": {},
   "source": [
    "Now, we can give these two extractors as steps to a `PipelineExtractor`, which will build a pipeline out of them which will execute them after each other and feed the output of the first step into the second step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f1be893-3e24-49ef-be23-e6b3ef92d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_extractor = PipelineExtractor(\n",
    "                steps=[\n",
    "                    src_extractor,\n",
    "                    std_extractor\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f25e0-9f57-45ab-8db9-a51c3af75c3c",
   "metadata": {},
   "source": [
    "Next, we will wrap our `PipelineExtractor* in an `Extraction`. This will allow us to configure where the output should be stored, which defaults to use and to run the extractor.\n",
    "\n",
    "We feed it our `PipelineExtractor` as the extractor, tell it to put the `Output` into our schema, and also give it our `Defaults`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9ebd37ab1ed766",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = Extraction(extractor=p_extractor,\n",
    "                        output=Output(db_schema=schema),\n",
    "                        defaults=defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfff27-e9fa-42c1-8594-5f5db60c8a91",
   "metadata": {},
   "source": [
    "Then the only step left is to define a convenience function which calls our preprocessing, and then run it in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f748392e800f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_text_ai_preprocessing():\n",
    "    extraction.run(ai_lab_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9edd47bd725c64",
   "metadata": {},
   "source": [
    "## Run the Preprocessing\n",
    "\n",
    "Time to run our preprocessing. First, let's verify how many entries our view has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a818260-5b8d-44c4-82b2-781a3dd908ef",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql7"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(ALL TICKET_ID) FROM \"{{schema}}\".\"{{view}}\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50d285-a323-4de8-937f-2efb1d2e4bf0",
   "metadata": {},
   "source": [
    "Then we call our preprocessing function. This will use our view as input, and produce new tables and views using the models we installed into the Exasol. \n",
    "\n",
    "Also, take note of the time this operation takes on your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80de77-a713-40ed-9c3f-532007c9abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_text_ai_preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4271c9",
   "metadata": {},
   "source": [
    "**Note**: If the previous operation fails with an error indicating a lost connection, please increase the size of your database and try again. The models are each around 1-2 GB in size and also need that much main memory on each node of your Database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd86aecabf8df2",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now, we will take a look at some of the tables and views our preprocessing has created for us. \n",
    "First, let's look at the tables created by our preprocessing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2049e6a00cd28",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TABLE_SCHEMA, TABLE_NAME FROM EXA_ALL_TABLES WHERE TABLE_SCHEMA='{{schema}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc3094-e88a-4054-97c3-7db52b4dc92f",
   "metadata": {},
   "source": [
    "As you can see, there are a number of new tables related to our preprocessing. There is our original data table `CUSTOMER_SUPPORT_TICKETS`, and a new log table `TXAIE_AUDIT_LOG` which we will take a closer look at below. The `DOCUMENTS` table contains our input texts together with an identifying Span, we will take a look at that as well.\n",
    " There is also a `DOCUMENTS_AI_LAB_TICKETS_SAMPLE` table, which contains IDs of the input text and documents, as well as the name of the column the input text originated from.\n",
    "This enables you to trace back documents(and their associated results) to the original input data point.\n",
    "\n",
    "And then there are 3 tables per step of our preprocessing. A main output table named after the preprocessing step, and some support tables. Multiple tables are required because the output content is usually normalized.\n",
    " The support tables are lookup tables and have names formatted like `<main_table_name>_LOOKUP_<normalized_column_name>`. We won't look at them in detail, but if you are curious, feel free to look at the contents of these tables on your own.\n",
    " Later we will discuss the contents of VIEWs build on top of these tables, which present them in a de-normalised form.\n",
    "\n",
    "If we want to find out how these new tables are structured, we can get a description from the Exasol Database. For example, let's see how the resulting `DOCUMENTS` table looks like.\n",
    "\n",
    "### DOCUMENTS Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3ba72-0767-444b-8c95-7711e9216b74",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql8"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESC \"{{schema}}\".DOCUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121aa5b-1b05-4d32-82e4-ca872e73736d",
   "metadata": {},
   "source": [
    "It looks like this table contains a `TEXT_DOC_ID`, `TEXT_CHAR_BEGIN`, `TEXT_CHAR_END` and a `TEXT` column.\n",
    "The `TEXT` column includes the text of the document.\n",
    "`TEXT_DOC_ID` is an ID assigned to each document.\n",
    " `TEXT_CHAR_BEGIN` and `TEXT_CHAR_END` indicate which parts of the original document each specific row contains. This triplet of `TEXT_DOC_ID`, `TEXT_CHAR_BEGIN` and `TEXT_CHAR_END` is called a \"Span\", and together builds an identifier for a section of text. You will encounter them for a lot of text-subsections. For example, found keywords contained in a text are also identified by a span in our result tables (see below).\n",
    "                                                                                                                                                        \n",
    "The usage of these Spans allows you to do various operations on top of these results, such as joining results on the document-id, or checking the order in which keywords appear in a document.\n",
    "\n",
    "We can also check the number of unique TEXT_DOC_IDs in our table:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab98a8e-4a1c-4ed9-9f63-2f3e33542795",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql9"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(ALL text_doc_id) FROM \"{{schema}}\".DOCUMENTS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded0dc4-b9e1-4e66-9a80-124e8cd4f00c",
   "metadata": {},
   "source": [
    "It's identical to the number of rows in our input view. So all the data was converted successfully.\n",
    "\n",
    "Now, let's look at what the content of our table looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb50cee-8e7d-40d4-bc87-f1664f466edf",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql10"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM \"{{schema}}\".DOCUMENTS WHERE TEXT_DOC_ID < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4255e3dc376f9fb",
   "metadata": {},
   "source": [
    "## Resulting Views\n",
    "\n",
    "There are also some new views:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530d44adfd951a3",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT VIEW_SCHEMA, VIEW_NAME FROM EXA_ALL_VIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7ba49e2779850",
   "metadata": {},
   "source": [
    "Text AI stores the results of the three preprocessing steps in tables, which contain the data in normalized form. So, for instance, instead of the topic name you will see a number in the table. The names are collected in a supporting table, named something like XYZ_LOOKUP.\n",
    "For easier usage, Text AI creates views which join the respective tables together to provide human-readable information. Such a view is created for each of the preprocessing steps.\n",
    "\n",
    "The `DOCUMENTS_AI_LAB_TICKETS_SAMPLE_VIEW` is a view on top of our input data, with the addition of the span identifier(`TEXT_DOC_ID`, `TEXT_CHAR_BEGIN`, `TEXT_CHAR_END`) for the text column of each row. This can be used to join the original data with the preprocessing results.\n",
    "\n",
    "![A diagramm showing multiple Table names with their respective columns. Starting at \"CUSTOMER_SUPPORT_TICKETS\" folowed by \"TICKETS_SAMPLE\", then flowing to \"DOCUMENTS\" and \"DOCUMENTS_AI_LAB_TICKETS_SAMPLE_VIEW\". The columns containing the text document span are highlighted.](images/data_model_1.drawio.png)\n",
    "\n",
    "Let's take a closer look at the results of the topic classification step in our preprocessing now. These can be found in the view `TOPIC_CLASSIFIER_VIEW`.\n",
    "\n",
    "### Topic Classifier View\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429842a118fff88c",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql11"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESC \"{{schema}}\".TOPIC_CLASSIFIER_VIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14884ff2-d063-4cce-8c6a-a9a3f5b611bb",
   "metadata": {},
   "source": [
    "This view contains the cross product of the input text and the topics. For each text-topic pair, it provides the computed `TOPIC_SCORE` between the text and the topic. The `TOPIC_SCORE` approximates a normalized relevance of the text with the topic.\n",
    "\n",
    "The value in the `TOPIC_RANK` column ranks the topics for each source document by their `TOPIC_SCORE` value. For our example, we had only two topics, so each document was assigned each of the topics, with different scores. The one with the higher score for a given document will have rank 1, the one with the lower score will have rank 2.\n",
    "\n",
    "There is also a column for error messages encountered during classification, as well as a `SETUP` column documenting which setup(i.e. model, model-settings) where used to obtain this result.\n",
    "\n",
    "As you remember, we wanted to use the classifier to differentiate our user tickets into \"urgent\" issues and \"non-urgent\" issues. So those are the topics we expect to see in the results. Let's check how these results look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b11b5-77e0-4a1e-bcde-5b1bea93a7b0",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql12"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM \"{{schema}}\".TOPIC_CLASSIFIER_VIEW LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fa3de-8cad-442d-900d-281460954a64",
   "metadata": {},
   "source": [
    "Next, we look at the identified named entities for our input documents. These can be found in the `NAMED_ENTITY_VIEW`.\n",
    "### Named Entity View:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096ed66-3d27-45e3-ab49-1dbc697dad0c",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql13"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESC \"{{schema}}\".NAMED_ENTITY_VIEW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62639933-e176-406f-9b9e-4ea3aeea6088",
   "metadata": {},
   "source": [
    "Similar to the `TOPIC_CLASSIFIER_VIEW`, the `NAMED_ENTITY_VIEW` also has the Span(`TEXT_DOC_ID`, `TEXT_CHAR_BEGIN`, `TEXT_CHAR_END`) identifying the input document the entity was found in. Then there are the found named entities in the `ENTITY` column, as well as an `ENTITY_TYPE` and an `ENTITY_SCORE`. The `ENTITY_TYPE` and `ENTITY_SCORE` are assigned to the entity by the model. Additionally, we also have an identifying span for the entity itself: `ENTITY_DOC_ID`, `ENTITY_CHAR_BEGIN`, `ENTITY_CHAR_END`. This span represents exactly where in our input data this entity was found.\n",
    "\n",
    "![a text with an id number. the text containings the named entity subtext \"GoPro Hero\". from the id, subtext begin and subtext end arrows are pointing to the id,begin,end of the entity span.](images/entity_span.drawio.png)\n",
    "\n",
    "Since the named entity was found in the text identified by `TEXT_DOC_ID, TEXT_CHAR_BEGIN, TEXT_CHAR_END`, it follows that `TEXT_DOC_ID`=`ENTITY_DOC_ID` for a given row. Similarly, both `ENTITY_CHAR_BEGIN` and `ENTITY_CHAR_END` are between `TEXT_CHAR_BEGIN` and `TEXT_CHAR_END`. You can use these spans for further processing down the line. For example, you could check how close together named entities of the same document were found, and then check if certain named entity clusters are indicative of different topics. However, this post-processing is not part of this tutorial.\n",
    "\n",
    "The `NAMED_ENTITY_VIEW` also includes an error message column and a setup column like the `TOPIC_CLASSIFIER_VIEW` above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc4c04-30b5-4e46-a8ba-dd09a311f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.displaylimit = 10 # we set this lower to the show only a preview of the views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574387a-ee93-4bb9-94b9-35776590daa4",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql14"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TEXT_DOC_ID, \n",
    "    TEXT_CHAR_BEGIN, \n",
    "    TEXT_CHAR_END,\n",
    "    ENTITY, \n",
    "    ENTITY_TYPE, \n",
    "    ENTITY_SCORE, \n",
    "    ENTITY_DOC_ID, \n",
    "    ENTITY_CHAR_BEGIN, \n",
    "    ENTITY_CHAR_END \n",
    "FROM \"{{schema}}\".NAMED_ENTITY_VIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7309e-7920-4f3c-8136-c814688f7884",
   "metadata": {},
   "source": [
    "### Keyword-Search View\n",
    "\n",
    "Lastly, our preprocessing created a view containing the results of the keyword search step, the `KEYWORD_SEARCH_VIEW`. This one is structured similar to the `NAMED_ENTITY_VIEW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a619417-1f99-4ed5-8590-eb719729430e",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql15"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESC \"{{schema}}\".KEYWORD_SEARCH_VIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3c167-1cc0-4287-a7aa-8dce75566781",
   "metadata": {},
   "source": [
    "The `TEXT_DOC_ID`, `TEXT_CHAR_BEGIN` and `TEXT_CHAR_END` are again the input document span. But instead of an entity with an entity-score and an entity span, we now have a keyword column, a keyword score and a span(`KEYWORD_DOC_ID`, `KEYWORD_CHAR_BEGIN`, `KEYWORD_CHAR_END`) identifying the found keyword in the text. Then, of course, the `ERROR_MESSAGE` and `SETUP` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1a0a6-de52-478c-b50d-f39c55f479ec",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql16"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TEXT_DOC_ID, \n",
    "    TEXT_CHAR_BEGIN, \n",
    "    TEXT_CHAR_END,\n",
    "    KEYWORD, \n",
    "    KEYWORD_SCORE, \n",
    "    KEYWORD_DOC_ID, \n",
    "    KEYWORD_CHAR_BEGIN, \n",
    "    KEYWORD_CHAR_END \n",
    "FROM \"{{schema}}\".KEYWORD_SEARCH_VIEW WHERE TEXT_DOC_ID < 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aca5b4450cbc9e70",
   "metadata": {},
   "source": [
    "You might notice some seemingly duplicated keywords for a given document. But take a look at the keyword spans of those \"duplicates\". They are different. This means the same keyword was found multiple times in the same document.\n",
    "\n",
    "### Result Summary\n",
    "\n",
    "Here is an overview of the data model our preprocessing created.\n",
    "    \n",
    "![A diagramm showing multiple Table names with their respective columns. Starting at \"DOCUMENTS\" and then the three result views. The columns containg the text document span are highlighted.](images/data_model_2.drawio.png)\n",
    "\n",
    "\n",
    "## Adding Data to Source View\n",
    "\n",
    "Now, let's try and run the preprocessing again, using the exact same input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009a399-80ef-4d70-977d-2e90514128e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_text_ai_preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55b907-449a-4f5b-86b3-27fa6e967c52",
   "metadata": {},
   "source": [
    "See how quickly it runs this time? This is because the Text AI does not compute results already computed in previous runs. We can test this behaviour further. Let's add more entries to our dataset, and see and see how long the preprocessing takes then.\n",
    "\n",
    "So, in the next call let's double the data in our input view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b5f8ea3-5a3f-4db1-8bfb-a6d2c361d378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW \"{{schema}}\".\"{{view}}\" AS \n",
    "SELECT * FROM \"{{schema}}\".\"{{table}}\" \n",
    "ORDER BY \"TICKET_ID\" \n",
    "LIMIT {{view_size}}*2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efbde6c-d1a5-4c46-b29f-2cba7784bc3d",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql17"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(ALL TICKET_ID) FROM \"{{schema}}\".\"{{view}}\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adbdf20-cbd7-4ba8-9660-25d0d52443ba",
   "metadata": {},
   "source": [
    "Once we run the preprocessing again, you would expect this run to take twice as long as the first run we did. However, thanks to the way the Text AI is implemented, it takes only roughly the same time as the first run. Text AI detects which documents where already processed and only processes new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac78916bcd213be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "run_text_ai_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffba3dd-6082-4bb7-addb-26e30ea0057b",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql18"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT (*) FROM \"{{schema}}\".DOCUMENTS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a458a9-9c3e-49e1-8e9c-0e8828d1fd25",
   "metadata": {},
   "source": [
    "Remember, the processing time is dependent on a lot of factors, such as the actual size of the data points, the batch size, parallelism per node, as well as available memory and number of nodes of the used Exasol Database. So the actual speedup you experience will differ from case to case.\n",
    "\n",
    "If you want to experiment with this further, feel free to, for example, add even more data. For this Notebook we did not demonstrate this, because the calls take a long time for demonstration purposes.\n",
    "\n",
    "## Audit Log\n",
    "\n",
    "Lastly, let's look at the audit log table Text AI has generated for us. This is a table documenting each run Text AI does on our ExasolDatabase. It contains information on runtime, how mana data entries were used or created, and error messages. This can be very helpful if you suspect a problem with one of your pipelines and want to know where it is coming from. Or if you are interested in seeing how much data came from a specific step, or which of the pipeline steps is taking too long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95edd057-947f-4249-a99c-7ae68210e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.displaylimit = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d9466-159f-47fe-b0eb-74cb77ae5821",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql19"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESC \"{{schema}}\".TXAIE_AUDIT_LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9896bb-289b-49a1-a5ea-9be7341d1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import option_context\n",
    "with open_pyexasol_connection(ai_lab_config, compression=True) as conn:\n",
    "    audit_log = conn.export_to_pandas(f\"\"\"\n",
    "        SELECT \n",
    "            RUN_ID,\n",
    "            DB_OBJECT_NAME,\n",
    "            EVENT_NAME,\n",
    "            ROW_COUNT,\n",
    "            LOG_TIMESTAMP \n",
    "        FROM \"{schema}\".TXAIE_AUDIT_LOG\n",
    "    \"\"\")\n",
    "    with option_context('display.max_rows', 20, 'display.max_colwidth', 1000):\n",
    "        display(audit_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c57149",
   "metadata": {},
   "source": [
    "You can now continue with the [Text AI Analytics Notebook](txaie_analytics.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
