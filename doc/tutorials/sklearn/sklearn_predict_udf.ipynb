{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e31a8e-3da8-416f-9fc5-13d1c23664c1",
   "metadata": {},
   "source": [
    "In this notebook we are going to create a universal UDF SET script that will use a trained scikit-learn model for making a prediction. In order to use this script one has to create and train a scikit-learn model or a pipeline and upload its pickle file into the BucketFS. The list of features supplied to the UDF should match those used in model training and/or pre-processing. The script emits the prediction labels. The output of the script can be multi-dimensional. It works similarly in regression and classification scenarios.\n",
    "\n",
    "To communicate with Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "Prior to using this notebook one needs to [create the database schema](setup_db.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0da0339-bedf-4433-be03-921650f3837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move this to a separate configuration notebook. Here we just need to load this configuration from a store.\n",
    "EXASOL_EXTERNAL_HOST_NAME = \"192.168.124.93\"\n",
    "EXASOL_HOST_PORT = \"8888\"\n",
    "EXASOL_EXTERNAL_HOST = f\"\"\"{EXASOL_EXTERNAL_HOST_NAME}:{EXASOL_HOST_PORT}\"\"\"\n",
    "EXASOL_USER = \"sys\"\n",
    "EXASOL_PASSWORD = \"exasol\"\n",
    "EXASOL_BUCKETFS_PORT = \"6666\"\n",
    "EXASOL_EXTERNAL_BUCKETFS_HOST = f\"\"\"{EXASOL_EXTERNAL_HOST_NAME}:{EXASOL_BUCKETFS_PORT}\"\"\"\n",
    "EXASOL_BUCKETFS_USER = \"w\"\n",
    "EXASOL_BUCKETFS_PASSWORD = \"write\"\n",
    "EXASOL_BUCKETFS_USE_HTTPS = False\n",
    "EXASOL_BUCKETFS_URL_PREFIX = \"https://\" if EXASOL_BUCKETFS_USE_HTTPS else \"http://\"\n",
    "EXASOL_BUCKETFS_SERVICE = \"bfsdefault\"\n",
    "EXASOL_BUCKETFS_BUCKET = \"default\"\n",
    "EXASOL_BUCKETFS_PATH = f\"/buckets/{EXASOL_BUCKETFS_SERVICE}/{EXASOL_BUCKETFS_BUCKET}\" # Filesystem-Path to the read-only mounted BucketFS inside the running UDF Container\n",
    "EXASOL_SCRIPT_LANGUAGE_NAME = \"PYTHON3_60\"\n",
    "EXASOL_UDF_FLAVOR = \"python3-ds-EXASOL-6.0.0\"\n",
    "EXASOL_UDF_RELEASE= \"20190116\"\n",
    "EXASOL_UDF_CLIENT = \"exaudfclient\" # or for newer versions of the flavor exaudfclient_py3\n",
    "EXASOL_SCRIPT_LANGUAGES = f\"{EXASOL_SCRIPT_LANGUAGE_NAME}=localzmq+protobuf:///{EXASOL_BUCKETFS_SERVICE}/{EXASOL_BUCKETFS_BUCKET}/{EXASOL_UDF_FLAVOR}?lang=python#buckets/{EXASOL_BUCKETFS_SERVICE}/{EXASOL_BUCKETFS_BUCKET}/{EXASOL_UDF_FLAVOR}/exaudf/{EXASOL_UDF_CLIENT}\";\n",
    "EXASOL_SCHEMA = \"IDA\"\n",
    "\n",
    "connection_params = {\"dns\": EXASOL_EXTERNAL_HOST, \"user\": EXASOL_USER, \"password\": EXASOL_PASSWORD, \"compression\": True}\n",
    "\n",
    "params = {\n",
    "    \"script_languages\": EXASOL_SCRIPT_LANGUAGES,\n",
    "    \"script_language_name\": EXASOL_SCRIPT_LANGUAGE_NAME,\n",
    "    \"schema\": EXASOL_SCHEMA,\n",
    "    \"EXASOL_BUCKETFS_PORT\": EXASOL_BUCKETFS_PORT,\n",
    "    \"EXASOL_BUCKETFS_USER\": EXASOL_BUCKETFS_USER,\n",
    "    \"EXASOL_BUCKETFS_PASSWORD\": EXASOL_BUCKETFS_PASSWORD,\n",
    "    \"EXASOL_BUCKETFS_USE_HTTPS\": EXASOL_BUCKETFS_USE_HTTPS,\n",
    "    \"EXASOL_BUCKETFS_BUCKET\": EXASOL_BUCKETFS_BUCKET,\n",
    "    \"EXASOL_BUCKETFS_PATH\": EXASOL_BUCKETFS_PATH\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c74dbb1-e40b-427e-9140-fc33ded4798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prediction script took: 38.46ms\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import pyexasol\n",
    "from stopwatch import Stopwatch\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Create script to test the model\n",
    "sql = textwrap.dedent(\"\"\"\\\n",
    "CREATE OR REPLACE PYTHON3 SET SCRIPT\n",
    "{schema!i}.SKLEARN_PREDICT(...)\n",
    "EMITS(...) AS\n",
    "\n",
    "# Generic scikit-learn predictor that runs a prediction for a data batch.\n",
    "# Loads a scikit-learn model or a pipeline from the specified file. Calls its `predict` method\n",
    "# passing to it all provided data columns. Emits sample IDs and the output of the model.\n",
    "#\n",
    "# Note that the model should not include features' names!\n",
    "# \n",
    "# Input columns:\n",
    "#    [0]:  Full BucketFS path to the model file;\n",
    "#    [1]:  Sample ID, can be the ROWID of the test batch.\n",
    "#    [2+]: Feature columns.\n",
    "#\n",
    "# Output columns:\n",
    "#    [0]:  Sample ID copied from the input.\n",
    "#    [1+]: Model output.\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def run(ctx):\n",
    "    # Load model from EXABucket\n",
    "    with open(ctx[0], 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # Stream the data through the model to reduce the required main memory of the UDF.\n",
    "    # This allows running the UDF on larger datasets.\n",
    "    while True:\n",
    "        # Read the input skipping the first column which holds the model path.\n",
    "        X_pred = ctx.get_dataframe(num_rows=1000, start_col=1)\n",
    "        if X_pred is None:\n",
    "            break\n",
    "\n",
    "        # Call the model to get the predictions. Omit the first column in the input\n",
    "        # which holds the sample ids.\n",
    "        df_features = X_pred.drop(X_pred.columns[0], axis=1)\n",
    "        y_pred = model.predict(df_features)\n",
    "\n",
    "        # Combine predictions with the sample ids.\n",
    "        df_rowid = X_pred[X_pred.columns[0]].reset_index(drop=True)\n",
    "        df_pred = pd.concat((df_rowid, pd.DataFrame(y_pred)), axis=1)\n",
    "\n",
    "        # Output data\n",
    "        ctx.emit(df_pred)\n",
    "/\n",
    "\"\"\")\n",
    "\n",
    "with pyexasol.connect(dsn=EXASOL_EXTERNAL_HOST, user=EXASOL_USER, password=EXASOL_PASSWORD, compression=True) as conn:\n",
    "    conn.execute(query=sql, query_params=params)\n",
    "\n",
    "print(f\"Creating prediction script took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eac55c-52c1-41e1-8df4-41958d994bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
