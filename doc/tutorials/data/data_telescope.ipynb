{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5caa09-76ee-43d5-b999-b185b85ff046",
   "metadata": {},
   "source": [
    "Let's load data simulating registration of high energy gamma particles in an atmospheric Cherenkov telescope. <a href=\"https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope\" target=\"_blank\" rel=\"noopener\">Follow this link</a> to get details about this dataset.\n",
    "\n",
    "To execute queries and upload data to Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "Prior to using this notebook one needs to [create the database schema](../setup_db.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082ac10d-1e98-4513-a52b-e3c74760c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move this to a separate configuration notebook. Here we just need to load this configuration from a store.\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SandboxConfig:\n",
    "    EXTERNAL_HOST_NAME = \"192.168.124.93\"\n",
    "    HOST_PORT = \"8888\"\n",
    "\n",
    "    @property\n",
    "    def EXTERNAL_HOST(self):\n",
    "        return f\"\"\"{self.EXTERNAL_HOST_NAME}:{self.HOST_PORT}\"\"\"\n",
    "\n",
    "    USER = \"sys\"\n",
    "    PASSWORD = \"exasol\"\n",
    "    BUCKETFS_PORT = \"6666\"\n",
    "    BUCKETFS_USER = \"w\"\n",
    "    BUCKETFS_PASSWORD = \"write\"\n",
    "    BUCKETFS_USE_HTTPS = False\n",
    "    BUCKETFS_SERVICE = \"bfsdefault\"\n",
    "    BUCKETFS_BUCKET = \"default\"\n",
    "\n",
    "    @property\n",
    "    def EXTERNAL_BUCKETFS_HOST(self):\n",
    "        return f\"\"\"{self.EXTERNAL_HOST_NAME}:{self.BUCKETFS_PORT}\"\"\"\n",
    "\n",
    "    @property\n",
    "    def BUCKETFS_URL_PREFIX(self):\n",
    "        return \"https://\" if self.BUCKETFS_USE_HTTPS else \"http://\"\n",
    "\n",
    "    @property\n",
    "    def BUCKETFS_PATH(self):\n",
    "        # Filesystem-Path to the read-only mounted BucketFS inside the running UDF Container\n",
    "        return f\"/buckets/{self.BUCKETFS_SERVICE}/{self.BUCKETFS_BUCKET}\"\n",
    "\n",
    "    SCRIPT_LANGUAGE_NAME = \"PYTHON3_60\"\n",
    "    UDF_FLAVOR = \"python3-ds-EXASOL-6.0.0\"\n",
    "    UDF_RELEASE= \"20190116\"\n",
    "    UDF_CLIENT = \"exaudfclient\" # or for newer versions of the flavor exaudfclient_py3\n",
    "    SCHEMA = \"IDA\"\n",
    "\n",
    "    @property\n",
    "    def SCRIPT_LANGUAGES(self):\n",
    "        return f\"\"\"{self.SCRIPT_LANGUAGE_NAME}=localzmq+protobuf:///{self.BUCKETFS_SERVICE}/\n",
    "            {self.BUCKETFS_BUCKET}/{self.UDF_FLAVOR}?lang=python#buckets/{self.BUCKETFS_SERVICE}/\n",
    "            {self.BUCKETFS_BUCKET}/{self.UDF_FLAVOR}/exaudf/{self.UDF_CLIENT}\"\"\";\n",
    "\n",
    "    @property\n",
    "    def connection_params(self):\n",
    "        return {\"dns\": self.EXTERNAL_HOST, \"user\": self.USER, \"password\": self.PASSWORD, \"compression\": True}\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return {\n",
    "            \"script_languages\": self.SCRIPT_LANGUAGES,\n",
    "            \"script_language_name\": self.SCRIPT_LANGUAGE_NAME,\n",
    "            \"schema\": self.SCHEMA,\n",
    "            \"BUCKETFS_PORT\": self.BUCKETFS_PORT,\n",
    "            \"BUCKETFS_USER\": self.BUCKETFS_USER,\n",
    "            \"BUCKETFS_PASSWORD\": self.BUCKETFS_PASSWORD,\n",
    "            \"BUCKETFS_USE_HTTPS\": self.BUCKETFS_USE_HTTPS,\n",
    "            \"BUCKETFS_BUCKET\": self.BUCKETFS_BUCKET,\n",
    "            \"BUCKETFS_PATH\": self.BUCKETFS_PATH\n",
    "        }\n",
    "\n",
    "conf = SandboxConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4f723-f2d2-4841-8dbf-6df3bde54a64",
   "metadata": {},
   "source": [
    "First we will load the data into pandas DataFrame.\n",
    "We will name the column as per their description (see Additional Variable Information section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab1e6a9-b640-419b-bc8e-b4379a43666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the data took: 1.61s\n",
      "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
      "0   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
      "1  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
      "2   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
      "3   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
      "4   51.6240   21.1502  2.9085  0.2420  0.1340   50.8761  43.1887    9.8145   \n",
      "\n",
      "    fAlpha    fDist class  \n",
      "0   6.3609  205.261     g  \n",
      "1  76.9600  256.788     g  \n",
      "2  10.4490  116.737     g  \n",
      "3   4.6480  356.462     g  \n",
      "4   3.6130  238.098     g  \n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import tempfile\n",
    "from zipfile import ZipFile\n",
    "from contextlib import ExitStack\n",
    "import pandas as pd\n",
    "from stopwatch import Stopwatch\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "DATA_URL = \"https://archive.ics.uci.edu/static/public/159/magic+gamma+telescope.zip\"\n",
    "DATA_FILE = \"magic04.data\"\n",
    "\n",
    "resp = urlopen(DATA_URL)\n",
    "with ExitStack() as stack:\n",
    "    f = stack.enter_context(tempfile.TemporaryFile())\n",
    "    f.write(resp.read())\n",
    "    print(f\"Downloading the data took: {stopwatch}\")\n",
    "\n",
    "    f.seek(0)\n",
    "    z = stack.enter_context(ZipFile(f))\n",
    "    f = stack.enter_context(z.open(DATA_FILE, \"r\"))\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "column_names = [\n",
    "    'fLength',   # major axis of ellipse [mm]\n",
    "    'fWidth',    # minor axis of ellipse [mm] \n",
    "    'fSize',     # 10-log of sum of content of all pixels [in #phot]\n",
    "    'fConc',     # ratio of sum of two highest pixels over fSize  [ratio]\n",
    "    'fConc1',    # ratio of highest pixel over fSize  [ratio]\n",
    "    'fAsym',     # distance from highest pixel to center, projected onto major axis [mm]\n",
    "    'fM3Long',   # 3rd root of third moment along major axis  [mm] \n",
    "    'fM3Trans',  # 3rd root of third moment along minor axis  [mm]\n",
    "    'fAlpha',    # angle of major axis with vector to origin [deg]\n",
    "    'fDist',     # distance from origin to center of ellipse [mm]\n",
    "    'class'      # g,h - gamma (signal), hadron (background)\n",
    "]\n",
    "df.columns = column_names\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b6554-2b2e-4053-bea5-b69196218bfb",
   "metadata": {},
   "source": [
    "Let's split data randomly into train and test sets. We will then create two tables - TELESCOPE_TRAIN and TELESCOPE_TEST - and load the datasets into these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9726bbfb-7d4b-4dbf-97f6-2c70260c1bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 15215 rows into TRAIN.\n",
      "Imported 3804 rows into TEST.\n",
      "Importing the data took: 529.66ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pyexasol\n",
    "\n",
    "# Split the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "column_desc = [f'{c} {(\"DECIMAL(18,4)\" if c.startswith(\"f\") else \"CHAR(1)\")}' for c in column_names]\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "\n",
    "# Create Exasol connection\n",
    "with pyexasol.connect(dsn=conf.EXTERNAL_HOST, user=conf.USER, password=conf.PASSWORD, compression=True) as conn:\n",
    "\n",
    "    # Create tables\n",
    "    sql = f'CREATE OR REPLACE TABLE {{schema!i}}.TELESCOPE_TRAIN({\", \".join(column_desc)})'\n",
    "    conn.execute(query=sql, query_params=conf.params)\n",
    "    sql = 'CREATE OR REPLACE TABLE {schema!i}.TELESCOPE_TEST LIKE {schema!i}.TELESCOPE_TRAIN'\n",
    "    conn.execute(query=sql, query_params=conf.params)\n",
    "\n",
    "    # Import data into Exasol\n",
    "    conn.import_from_pandas(df_train, (conf.SCHEMA, \"TELESCOPE_TRAIN\"))\n",
    "    print(f\"Imported {conn.last_statement().rowcount()} rows into TRAIN.\")\n",
    "    conn.import_from_pandas(df_test, (conf.SCHEMA, \"TELESCOPE_TEST\"))\n",
    "    print(f\"Imported {conn.last_statement().rowcount()} rows into TEST.\")\n",
    "\n",
    "print(f\"Importing the data took: {stopwatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490c957-366e-425f-91ae-a645ccabbfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
