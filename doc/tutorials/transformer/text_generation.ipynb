{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73a1de2-05df-49ab-bec9-897f11dbe9a9",
   "metadata": {},
   "source": [
    "# Generative text model\n",
    "\n",
    "In this notebook we will load and use a generative language model that can produce a continuation for a given text. Learn more about the Text Generation task <a href=\"https://huggingface.co/tasks/text-generation\" target=\"_blank\" rel=\"noopener\">here</a>.\n",
    "\n",
    "We will be using a generic prediction UDF script. To execute queries and load data from Exasol database we will be using the <a href=\"https://github.com/exasol/pyexasol\" target=\"_blank\" rel=\"noopener\">`pyexasol`</a> module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Prior to using this notebook one needs to complete the follow steps:\n",
    "1. [Configure the sandbox](../sendbox_config.ipynb).\n",
    "2. [Initialize the Transformer Extension](te_init.ipynb).\n",
    "\n",
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b93680-738d-4b70-aa51-117b10d63915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: start using the secret store.\n",
    "\n",
    "from collections import UserDict\n",
    "\n",
    "class Secrets(UserDict):\n",
    "    \"\"\"This class mimics the Secret Store we will start using soon.\"\"\"\n",
    "\n",
    "    def save(self, key: str, value: str) -> \"Secrets\":\n",
    "        self[key] = value\n",
    "        return self\n",
    "\n",
    "# For now just hardcode the configuration.\n",
    "sb_config = Secrets({\n",
    "    'EXTERNAL_HOST_NAME': '192.168.124.93',\n",
    "    'HOST_PORT': '8888',\n",
    "    'USER': 'sys',\n",
    "    'PASSWORD': 'exasol',\n",
    "    'BUCKETFS_PORT': '6666',\n",
    "    'BUCKETFS_USER': 'w',\n",
    "    'BUCKETFS_PASSWORD': 'write',\n",
    "    'BUCKETFS_USE_HTTPS': 'False',\n",
    "    'BUCKETFS_SERVICE': 'bfsdefault',\n",
    "    'BUCKETFS_BUCKET': 'default',\n",
    "    'SCRIPT_LANGUAGE_NAME': 'PYTHON3_60',\n",
    "    'UDF_FLAVOR': 'python3-ds-EXASOL-6.0.0',\n",
    "    'UDF_RELEASE': '20190116',\n",
    "    'UDF_CLIENT': 'exaudfclient_py3',\n",
    "    'SCHEMA': 'IDA',\n",
    "    'TE_TOKEN': '',\n",
    "    'TE_TOKEN_CONN': '',\n",
    "    'TE_BFS_CONN': 'MyBFSConn',\n",
    "    'TE_BFS_DIR': 'my_storage',\n",
    "    'TE_MODELS_BFS_DIR': 'models',\n",
    "    'TE_MODELS_CACHE_DIR': 'models_cache'\n",
    "})\n",
    "\n",
    "EXTERNAL_HOST = f\"{sb_config.get('EXTERNAL_HOST_NAME')}:{sb_config.get('HOST_PORT')}\"\n",
    "WEBSOCKET_URL = f\"exa+websocket://{sb_config.get('USER')}:{sb_config.get('PASSWORD')}\" \\\n",
    "    f\"@{EXTERNAL_HOST}/{sb_config.get('SCHEMA')}?SSLCertificate=SSL_VERIFY_NONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d11a1d4-051d-4d21-990a-660beaeb8f0c",
   "metadata": {},
   "source": [
    "## Get language model\n",
    "\n",
    "To demonstrate the text generation task we will use [Open Pretrained Transformers (OPT)](https://huggingface.co/facebook/opt-125m), a decoder-only pre-trained transformer from Facebook.\n",
    "\n",
    "We need to load the model from the Huggingface hub into the BucketFS. This could potentially be a long process. Unfortunately we cannot tell exactly when it has finished. Notebook's hourglass may not be a reliable indicator. BucketFS will still be doing some work when the call issued by the notebook returns. Please wait for few moments after that, before querying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d73c9b44-93a0-4df3-9a8e-54e182027d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the name of the model at the Huggingface Hub\n",
    "MODEL_NAME = 'facebook/opt-125m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57029a52-064b-4fda-80bf-289cce50ffc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████| 685/685 [00:00<00:00, 80.6kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████████████████████████████████████████████████████████| 651/651 [00:00<00:00, 996kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|███████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 5.27MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 3.05MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████████████████████████████████████████████████████████| 441/441 [00:00<00:00, 325kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████| 251M/251M [00:14<00:00, 17.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "%run ./model_retrieval.ipynb\n",
    "load_huggingface_model(MODEL_NAME, sb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efa927-aa78-4b80-9b78-25e722904217",
   "metadata": {},
   "source": [
    "## Use language model\n",
    "\n",
    "Let's put the start of our conversation in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa3998b7-d886-4b0c-b0d2-92e54cc27b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_TEXT = 'The bar-headed goose can fly at much'\n",
    "\n",
    "# Make sure our texts can be used in an SQL statement.\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56498899-79f8-471e-8337-983184dcd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put a limit on the length of text the model can generate in one call.\n",
    "# The limit is specified in the number of characters.\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94a45b81-29e3-40f8-9bb8-4b7a5c6eb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyexasol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1dd67-ffed-4bf8-9ee7-a1e003cdbcc6",
   "metadata": {},
   "source": [
    "We will be updating this variable at every call to the model.\n",
    "Please run the next cell multiple times to see how the text evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51b0d826-519a-4e03-9ce0-3827d0756f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bar-headed goose can fly at much higher speeds than the average goose.\n",
      "I'm not sure if you're being sarcastic or not, but the bar-headed goose is\n"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT {sb_config.get(\"SCHEMA\")}.TE_TEXT_GENERATION_UDF(\n",
    "    NULL,\n",
    "    '{sb_config.get(\"TE_BFS_CONN\")}',\n",
    "    '{sb_config.get(\"TE_TOKEN_CONN\")}',\n",
    "    '{sb_config.get(\"TE_MODELS_BFS_DIR\")}',\n",
    "    '{MODEL_NAME}',\n",
    "    '{MY_TEXT}',\n",
    "    {MAX_LENGTH},\n",
    "    True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with pyexasol.connect(dsn=EXTERNAL_HOST, user=sb_config.get('USER'), password=sb_config.get('PASSWORD'), compression=True) as conn:\n",
    "    result = conn.export_to_pandas(query_or_table=sql).squeeze()\n",
    "    MY_TEXT = result['GENERATED_TEXT']\n",
    "    # The error can be observed at result['ERROR_MESSAGE']\n",
    "\n",
    "print(MY_TEXT)\n",
    "MY_TEXT = MY_TEXT.replace(\"'\", \"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30974b1a-a5b5-44d9-97c8-774be0dd4608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
